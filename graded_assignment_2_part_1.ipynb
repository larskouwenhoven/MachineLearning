{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graded Lab Assignment 2: Evaluate classifiers (10 points)\n",
    " \n",
    "In this assignment you will optimize and compare the perfomance of a parametric (logistic regression) and non-parametric (k-nearest neighbours) classifier on the MNIST dataset.\n",
    "\n",
    "Publish your notebook (ipynb file) to your Machine Learning repository on Github ON TIME. We will check the last commit on the day of the deadline.  \n",
    "\n",
    "### Deadline Friday, November 17, 23:59.\n",
    "\n",
    "This notebook consists of three parts: design, implementation, results & analysis. \n",
    "We provide you with the design of the experiment and you have to implement it and analyse the results.\n",
    "\n",
    "### Criteria used for grading\n",
    "* Explain and analyse all results.\n",
    "* Make your notebook easy to read. When you are finished take your time to review it!\n",
    "* You do not want to repeat the same chunks of code multiply times. If your need to do so, write a function. \n",
    "* The implementation part of this assignment needs careful design before you start coding. You could start by writing pseudocode.\n",
    "* In this exercise the insights are important. Do not hide them somewhere in the comments in the implementation, but put them in the Analysis part\n",
    "* Take care that all the figures and tables are well labeled and numbered so that you can easily refer to them.\n",
    "* A plot should have a title and axes labels.\n",
    "* You may find that not everything is 100% specified in this assignment. That is correct! Like in real life you probably have to make some choices. Motivate your choices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading points distribution\n",
    "\n",
    "* Implementation 5 points\n",
    "* Results and analysis 5 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design of the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You do not have to keep the order of this design and are allowed to alter it if you are confident.\n",
    "* Import all necessary modules. Try to use as much of the available functions as possible. \n",
    "* Use the provided train and test set of MNIST dataset.\n",
    "* Pre-process data eg. normalize/standardize, reformat, etc.           \n",
    "  Do whatever you think is necessary and motivate your choices. What if it also works now???\n",
    "* (1) Train logistic regression and k-nn using default settings.\n",
    "* Use 10-fold cross validation for each classifier to optimize the performance for one parameter: \n",
    "    * consult the documentation on how cross validation works in sklearn (important functions:             cross_val_score(), GridSearchCV()).\n",
    "    * Optimize k for k-nn,\n",
    "    * for logistic regression focus on the regularization parameter,\n",
    "* (2) Train logistic regression and k-nn using optimized parameters.\n",
    "* Show performance on the cross-validation set for (1) and (2) for both classifiers: \n",
    "    * report the average cross validation error rates (alternatively, the average accuracies - it's up to you) and standard deviation,\n",
    "    * plot the average cross valildation errors (or accuracies) for different values of the parameter that you tuned. \n",
    "* Compare performance on the test set for two classifiers:\n",
    "    * produce the classification report for both classifiers, consisting of precision, recall, f1-score. Explain and analyse the results.\n",
    "    * print confusion matrix for both classifiers and compare whether they missclassify the same  classes. Explain and analyse the results.\n",
    "* Discuss your results.\n",
    "* BONUS: only continue with this part if you are confident that your implemention is complete \n",
    "    * tune more parameters of logistic regression\n",
    "    * add additional classifiers (NN, Naive Bayes, decision tree), \n",
    "    * analyse additional dataset (ex. Iris dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import numpy as np \n",
    "# load mnist dataset and split in train and test set.\n",
    "digits = load_digits()\n",
    "X_train_mnist = np.reshape(digits.images[:1500],(1500,64))\n",
    "X_test_mnist = np.reshape(digits.images[1500:],(297,64))\n",
    "y_train_mnist = digits.target[:1500]\n",
    "y_test_mnist = digits.target[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import the necessary modules \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   5. ...,   0.   0.   0.]\n",
      " [  0.   0.   0. ...,  10.   0.   0.]\n",
      " [  0.   0.   0. ...,  16.   9.   0.]\n",
      " ..., \n",
      " [  0.   0.   0. ...,   9.   0.   0.]\n",
      " [  0.   1.   9. ...,   9.   1.   0.]\n",
      " [  0.   5.  16. ...,   8.   6.   0.]] \n",
      "\n",
      "[[  0.   0.   0. ...,  13.   2.   0.]\n",
      " [  0.   0.   2. ...,   0.   0.   0.]\n",
      " [  0.   0.   0. ...,   0.   0.   0.]\n",
      " ..., \n",
      " [  0.   0.   1. ...,   6.   0.   0.]\n",
      " [  0.   0.   2. ...,  12.   0.   0.]\n",
      " [  0.   0.  10. ...,  12.   1.   0.]] \n",
      "\n",
      "[0 1 2 ..., 6 3 2] \n",
      "\n",
      "[1 7 4 6 3 1 3 9 1 7 6 8 4 3 1 4 0 5 3 6 9 6 1 7 5 4 4 7 2 8 2 2 5 7 9 5 4\n",
      " 8 8 4 9 0 8 9 8 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 9 0 1 2 3 4 5 6 7 8 9 0\n",
      " 9 5 5 6 5 0 9 8 9 8 4 1 7 7 3 5 1 0 0 2 2 7 8 2 0 1 2 6 3 3 7 3 3 4 6 6 6\n",
      " 4 9 1 5 0 9 5 2 8 0 1 7 6 3 2 1 7 4 6 3 1 3 9 1 7 6 8 4 3 1 4 0 5 3 6 9 6\n",
      " 1 7 5 4 4 7 2 2 5 7 9 5 4 4 9 0 8 9 8 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7\n",
      " 8 9 0 1 2 3 4 5 6 7 8 9 0 9 5 5 6 5 0 9 8 9 8 4 1 7 7 3 5 1 0 0 2 2 7 8 2\n",
      " 0 1 2 6 3 3 7 3 3 4 6 6 6 4 9 1 5 0 9 5 2 8 2 0 0 1 7 6 3 2 1 7 4 6 3 1 3\n",
      " 9 1 7 6 8 4 3 1 4 0 5 3 6 9 6 1 7 5 4 4 7 2 8 2 2 5 7 9 5 4 8 8 4 9 0 8 9\n",
      " 8] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print the data such that we can visualize it\n",
    "print((X_train_mnist), \n",
    "      '\\n')\n",
    "print((X_test_mnist),\n",
    "      '\\n')\n",
    "print((y_train_mnist),\n",
    "      '\\n')\n",
    "print((y_test_mnist),\n",
    "      '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no need to standardize or normalize our data because of the folliwing reasons.\n",
    "\n",
    "If we look at the data printed above we see that everything is within the range of 1 to 20, which is an small enough range.\n",
    "\n",
    "For the K-nn algorithm, this algorithm computes the distances to its neighbours and then decides according to its k nearest neighbours what the class of the node is. The algorithm does not become faster if we make our data be in a shorter range, which will lead do smaller distances between the points. \n",
    "\n",
    "For logistic regression, we standardize or normalize our data, since if very big number it becomes very hard to perform matrix multiplicationwe have quadratic matrix multiplications. However, we know that we are dealing with linear logistic regression, and the range of our data set is narrow as well so therefore we do not have to standardize or normalize our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1}\n",
      "{'C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "#Train logistic regression and k-nn using default settings.\n",
    "#Optimize k for k-nn,\n",
    "Knn = KNeighborsClassifier()\n",
    "parametersK = {'n_neighbors': np.arange(1,20)} \n",
    "clfK = GridSearchCV(Knn, parametersK)\n",
    "clfK.fit(X_train_mnist, y_train_mnist)\n",
    "print(clfK.best_params_)\n",
    "\n",
    "\n",
    "#for logistic regression focus on the regularization parameter\n",
    "LR = LogisticRegression()\n",
    "parametersLR = {'C': np.arange(0.01, 10)}\n",
    "clf = GridSearchCV(LR, parametersLR) \n",
    "clf.fit(X_train_mnist, y_train_mnist)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we cross validate in these functions and determine the average accuracy and standard deviation\n",
    "\n",
    "def av_accuracy(type, Xset, Yset):\n",
    "    av_acc = np.mean(cross_val_score(type, Xset, Yset, cv=10))\n",
    "    return av_acc\n",
    "\n",
    "def standarddev(type, Xset, Yset):\n",
    "    std = np.std(cross_val_score(type, Xset, Yset, cv=10))\n",
    "    return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy under Logistic Regression with default parameters is:         0.942841934708\n",
      "The standard deviation under Logistic Regression with default parameters is:       0.0179428426554 \n",
      "\n",
      "The average accuracy under K-nn with default parameters is:                        0.969568068457\n",
      "The standard deviation under K-nn with default parameters is:                      0.021372714321 \n",
      "\n",
      "The average accuracy under Logistic Regression with optimized parameters is:       0.952847426302\n",
      "The standard deviation under Logistic Regression with optimized parameters is:     0.0176755181395 \n",
      "\n",
      "The average accuracy under K-nn with optimized parameters is:                      0.978226258333\n",
      "The standard deviation under K-nn with optimized parameters is:                    0.023415643686\n",
      "\n",
      " [ 0.90967742  0.96052632  0.9602649   0.94666667  0.94666667  0.94\n",
      "  0.97315436  0.97315436  0.95945946  0.95890411] \n",
      "\n",
      "[ 0.92258065  1.          0.98675497  0.98        0.98666667  0.94666667\n",
      "  0.98657718  0.97986577  1.          0.99315068]\n"
     ]
    }
   ],
   "source": [
    "#print the accuracies and standard deviation of Logistic regression and K-nn using default parameters on train set\n",
    "print(\"The average accuracy under Logistic Regression with default parameters is:        \", \n",
    "      av_accuracy(LR, X_train_mnist, y_train_mnist))\n",
    "print(\"The standard deviation under Logistic Regression with default parameters is:      \", \n",
    "      standarddev(LR, X_train_mnist, y_train_mnist),\n",
    "     \"\\n\")\n",
    "\n",
    "print(\"The average accuracy under K-nn with default parameters is:                       \", \n",
    "      av_accuracy(Knn, X_train_mnist, y_train_mnist))\n",
    "print(\"The standard deviation under K-nn with default parameters is:                     \", \n",
    "      standarddev(Knn, X_train_mnist, y_train_mnist),\n",
    "     \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#Train logistic regression using optimized parameters.\n",
    "LR_opt = LogisticRegression(C=0.1)\n",
    "LR_opt.fit(X_train_mnist, y_train_mnist)\n",
    "\n",
    "#print the accuracies and standard deviation of Logistic regression and K-nn using optimized parameters on train set\n",
    "print(\"The average accuracy under Logistic Regression with optimized parameters is:      \", \n",
    "      av_accuracy(LR_opt, X_train_mnist, y_train_mnist))\n",
    "print(\"The standard deviation under Logistic Regression with optimized parameters is:    \", \n",
    "      standarddev(LR_opt, X_train_mnist, y_train_mnist),\n",
    "     \"\\n\")\n",
    "\n",
    "#Train K-nn using optimized parameters\n",
    "Knn_opt = KNeighborsClassifier(n_neighbors=1)\n",
    "Knn_opt.fit = (X_train_mnist, y_train_mnist)\n",
    "\n",
    "print(\"The average accuracy under K-nn with optimized parameters is:                     \", \n",
    "      av_accuracy(Knn_opt, X_train_mnist, y_train_mnist))\n",
    "print(\"The standard deviation under K-nn with optimized parameters is:                   \", \n",
    "      standarddev(Knn_opt, X_train_mnist, y_train_mnist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy under Logistic Regression with default parameters is:         0.917677388323\n",
      "The standard deviation under Logistic Regression with optimized parameters is:     0.048205432794 \n",
      "\n",
      "The average accuracy under K-nn with default parameters is:                        0.948066688389\n",
      "The standard deviation under K-nn with default parameters is:                      0.0490240354803 \n",
      "\n",
      "The average accuracy under Logistic Regression with optimized parameters is:       0.921078061723\n",
      "The standard deviation under Logistic Regression with optimized parameters is:     0.0514557440459 \n",
      "\n",
      "The average accuracy under K-nn with optimized parameters is:                      0.978226258333\n",
      "The standard deviation under K-nn with optimized parameters is:                    0.023415643686\n",
      "[ 0.79207921  0.91836735  0.91836735]\n",
      "[ 0.83168317  0.92857143  0.95918367]\n"
     ]
    }
   ],
   "source": [
    "#Print the average accuracies and standard deviations using default parameters of Logistic regression and \n",
    "#K-nn on the test set\n",
    "print(\"The average accuracy under Logistic Regression with default parameters is:        \", \n",
    "      av_accuracy(LR, X_test_mnist, y_test_mnist))\n",
    "print(\"The standard deviation under Logistic Regression with optimized parameters is:    \", \n",
    "      standarddev(LR, X_test_mnist, y_test_mnist),\n",
    "     \"\\n\")\n",
    "\n",
    "print(\"The average accuracy under K-nn with default parameters is:                       \", \n",
    "      av_accuracy(Knn, X_test_mnist, y_test_mnist))\n",
    "print(\"The standard deviation under K-nn with default parameters is:                     \", \n",
    "      standarddev(Knn, X_test_mnist, y_test_mnist),\n",
    "     \"\\n\")\n",
    "\n",
    "#Print the average accuracies and standard deviations using optimized parameters of Logistic regression and\n",
    "#K-nn on the test set\n",
    "print(\"The average accuracy under Logistic Regression with optimized parameters is:      \", \n",
    "      av_accuracy(LR_opt, X_test_mnist, y_test_mnist))\n",
    "print(\"The standard deviation under Logistic Regression with optimized parameters is:    \", \n",
    "      standarddev(LR_opt, X_test_mnist, y_test_mnist),\n",
    "     \"\\n\")\n",
    "\n",
    "print(\"The average accuracy under K-nn with optimized parameters is:                     \", \n",
    "      av_accuracy(Knn_opt, X_train_mnist, y_train_mnist))\n",
    "print(\"The standard deviation under K-nn with optimized parameters is:                   \", \n",
    "      standarddev(Knn_opt, X_train_mnist, y_train_mnist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1135d6080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115225b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot graph for different values of K\n",
    "\n",
    "#In the bonus I created a function for this, but when we use the function here it takes very long\n",
    "#for the function to output, therefore I create the points here \"manually\"\n",
    "Knn2 = KNeighborsClassifier(n_neighbors=2)\n",
    "Knn2.fit = (X_train_mnist, y_train_mnist)\n",
    "Knn3 = KNeighborsClassifier(n_neighbors=3)\n",
    "Knn3.fit = (X_train_mnist, y_train_mnist)\n",
    "Knn4 = KNeighborsClassifier(n_neighbors = 4)\n",
    "Knn4.fit = (X_train_mnist, y_train_mnist)\n",
    "Knn5 = KNeighborsClassifier(n_neighbors = 5)\n",
    "Knn5.fit = (X_train_mnist, y_train_mnist)\n",
    "Knn6 = KNeighborsClassifier(n_neighbors = 6)\n",
    "Knn6.fit = (X_train_mnist, y_train_mnist)\n",
    "Knn7 = KNeighborsClassifier(n_neighbors = 7)\n",
    "Knn7.fit = (X_train_mnist, y_train_mnist)\n",
    "\n",
    "\n",
    "plt.plot([1, 2, 3, 4,5,6,7], [av_accuracy(Knn_opt,X_train_mnist, y_train_mnist), av_accuracy(Knn2, X_train_mnist, y_train_mnist), av_accuracy(Knn3, X_train_mnist, y_train_mnist), av_accuracy(Knn4, X_train_mnist, y_train_mnist), av_accuracy(Knn5, X_train_mnist, y_train_mnist), av_accuracy(Knn6, X_train_mnist, y_train_mnist), av_accuracy(Knn7, X_train_mnist, y_train_mnist)], \"ro\")\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('number of neighbours')\n",
    "plt.title('plot different values of k')\n",
    "plt.show()\n",
    "\n",
    "#Plot graph for different values of C\n",
    "LR2 = LogisticRegression(C=0.1)\n",
    "LR2.fit(X_train_mnist, y_train_mnist)\n",
    "LR3 = LogisticRegression(C=1)\n",
    "LR3.fit(X_train_mnist, y_train_mnist)\n",
    "LR4 = LogisticRegression(C=10)\n",
    "LR4.fit(X_train_mnist, y_train_mnist)\n",
    "LR5 = LogisticRegression(C=0.05)\n",
    "LR5.fit(X_train_mnist, y_train_mnist)\n",
    "LR6 = LogisticRegression(C=0.07)\n",
    "LR6.fit(X_train_mnist, y_train_mnist)\n",
    "LR7 = LogisticRegression(C=0.3)\n",
    "LR7.fit(X_train_mnist, y_train_mnist)\n",
    "LR8 = LogisticRegression(C=0.5)\n",
    "LR8.fit(X_train_mnist, y_train_mnist)\n",
    "LR9 = LogisticRegression(C=0.7)\n",
    "LR9.fit(X_train_mnist, y_train_mnist)\n",
    "\n",
    "\n",
    "plt.plot([0.01, 0.05, 0.07, 0.1, 0.3, 0.5, 0.7, 1], [av_accuracy(LR_opt, X_train_mnist, y_train_mnist), av_accuracy(LR2, X_train_mnist, y_train_mnist), av_accuracy(LR3, X_train_mnist, y_train_mnist), av_accuracy(LR5, X_train_mnist, y_train_mnist), av_accuracy(LR6, X_train_mnist, y_train_mnist), av_accuracy(LR7, X_train_mnist, y_train_mnist), av_accuracy(LR8, X_train_mnist, y_train_mnist), av_accuracy(LR9, X_train_mnist, y_train_mnist)], 'ro')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('value of C')\n",
    "plt.title('plot different values for C')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report of Logistic regression classifier \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        27\n",
      "          1       0.97      1.00      0.98        31\n",
      "          2       1.00      1.00      1.00        27\n",
      "          3       1.00      1.00      1.00        30\n",
      "          4       1.00      1.00      1.00        33\n",
      "          5       1.00      1.00      1.00        30\n",
      "          6       1.00      1.00      1.00        30\n",
      "          7       1.00      1.00      1.00        30\n",
      "          8       1.00      0.96      0.98        28\n",
      "          9       1.00      1.00      1.00        31\n",
      "\n",
      "avg / total       1.00      1.00      1.00       297\n",
      "\n",
      "classification report of K-nearest-neighbour classifier \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        27\n",
      "          1       1.00      1.00      1.00        31\n",
      "          2       1.00      1.00      1.00        27\n",
      "          3       1.00      1.00      1.00        30\n",
      "          4       1.00      1.00      1.00        33\n",
      "          5       1.00      1.00      1.00        30\n",
      "          6       1.00      1.00      1.00        30\n",
      "          7       1.00      1.00      1.00        30\n",
      "          8       1.00      1.00      1.00        28\n",
      "          9       1.00      1.00      1.00        31\n",
      "\n",
      "avg / total       1.00      1.00      1.00       297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Give the classification report for the Logistic regression classifier\n",
    "y_true_LR = y_test_mnist\n",
    "y_pred_LR = LR_opt.predict(X_test_mnist)\n",
    "target_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] #since we have numbers ranging from 0 to 9 in the mnist data set. \n",
    "print(\"classification report of Logistic regression classifier \\n\", \"\\n\", classification_report(y_true_LR, y_pred_LR, target_names=target_names))\n",
    "\n",
    "#Give the classification report for the K-nn classifier\n",
    "y_true_knn = y_test_mnist\n",
    "knn_opt = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_opt.fit(X_test_mnist, y_test_mnist)\n",
    "y_pred_knn = knn_opt.predict(X_test_mnist)\n",
    "print(\"classification report of K-nearest-neighbour classifier \\n\", \"\\n\", classification_report(y_true_knn, y_pred_knn, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explenation of the classifcation report\n",
    "\n",
    "The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "\n",
    "The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples\n",
    "\n",
    "The f1-score can be interpreted as a weighted harmonic mean of the precision and recall, where an f1-score reaches its best value at 1 and worst score at 0.\n",
    "The f1-score weights recall more than precision by a factor of beta. beta == 1.0 means recall and precision are equally important\n",
    "\n",
    "The support is the number of occurrences of each class in y_true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusing matrix of Logistic Regression classifier \n",
      "\n",
      "[[27  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 31  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 27  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 30  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 33  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 30  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 30  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 30  0  0]\n",
      " [ 0  1  0  0  0  0  0  0 27  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 31]]\n",
      "\n",
      "\n",
      " Confusion matrix of K-nearest-neighbour classifier \n",
      "\n",
      "[[27  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 31  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 27  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 30  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 33  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 30  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 30  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 30  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 31]]\n"
     ]
    }
   ],
   "source": [
    "#Give the confusion matrix for the logistic regression classifier\n",
    "print(\"Confusing matrix of Logistic Regression classifier \\n\")\n",
    "print(confusion_matrix(y_true_LR, y_pred_LR))\n",
    "\n",
    "#Give the confusion matrix for the logistic regression classifier\n",
    "print(\"\\n\\n Confusion matrix of K-nearest-neighbour classifier \\n\")\n",
    "print(confusion_matrix(y_true_knn, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the confusion matrix, the rows represent the actual numbers going from 0 to 9 and the columns represent the numbers classified by the classifier going from 0 to 9. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and analysis of the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see that over all in this experiment, K-nn works slightly better than Logistic Regression. When we look at the accuracies with optimized parameters, we see that the accuracy of K-nn is 0.978226258333 with optimized parameters whearas that of Logistic Regression is 0.952847426302 with optimized parameters. \n",
    "\n",
    "When we plot the accuracies of K-nn classifier for different values of k, we see that the accuracy is the highest for 1 neighbour. We also see that the accuracy for 3 neighbours is slightly higher than the accuracy for 2 neighbours, but a lot lower than the accuracy for 1 neighbour. For 4 and 5 neighbours the accuracy is even lower. What stands the accuracies for the odd number of neighbous is almost always higher than the accuracy for the even number before that number. We see that the accuracy for n=3 is higher than n=2 and the accuracy for n=5 for n = 4. This is only not the case for n = 7. This at first seems contradicting, but we know that we can always determine to which class a point belongs if we take an odd number for k, whereas if we take an even number for k, we have to perform additional operations to make sure that we can always identify this point. It could be the case that these additional operations affect the accuracy in a negative way, and therefore an odd number for k has a higher accuracy. \n",
    "\n",
    "When we plot the accuracies for different values of C for logistic regression, we see that for almost all instances, the accuracy becomes lower for higher values of C. This is only not the case for C = 0.07, for that point the accuracy is suddenly a lot lower. \n",
    "\n",
    "If we look at the classification report of K-nn, we notice the following things. \n",
    "We see that the precision, recall and f1-score are 1 for every instance of K-nn. \n",
    "\n",
    "The fact that the precision is 1 means that tp / (tp + fp) is equal to 1. This means that tp needs to be equal to (tp + fp) which means that fp = 0. So we see that in the K-nn classifier, there are no false positives. \n",
    "\n",
    "The fact that the recall is 1 means that the ratio tp / (tp + fn) is 1. This also means that tp needs to be equal to (tp + fn), which means that fn = 0. Therefore, we see that in the K-nn classifier, we do not have false negatives.\n",
    "\n",
    "By combining this information we see that we have no false positives and no false negatives, which means that we do not have any wrongly classified instances. \n",
    "\n",
    "Since the f1-score is the weighted harmonic mean of the precision and recall and the precision and recall both are 1, it makes sense that the f1-score is 1 as well. \n",
    "\n",
    "In the classification report of Logistic Regression, we see that the average precision, recall and f1-score are respectively 0.90, 0.89, 0.89. As we have shown above, the fact that the precision is 0.90, means that 10% of what the logisic classifier classifies as positive, are actually false positives.\n",
    "\n",
    "The fact that the recall ratio is 89 means that only 89% of all our actual positive instances is classified as an positive instance by our classifier, thus 11% of our true positives are classified as negatives by the Logistic Regression classifier. \n",
    "\n",
    "Since the f1-score is the weighted harmonic mean of the precision and recall and the precision and recall are 0.90 and 0.89 respectivily, it makes sense that the f1-score is 0.89.\n",
    "\n",
    "If we look at the precision and recall scores for our digits for the logistic regression classifier individually, we notice that the recall ratio of the 3 is relatively low, namely 0.63. This thus means that we have a lot of actual 3's which are not classified as 3's by the classifier. Moreover, we see that the precision ratio of 8 is relatively low, namely 0.68. This means that we classify a lot of numbers as 8's which are actually not 8's. As 3 and 8 look similar, it could be the case that many 3's are being classified as 8's by our logistic regression classifier. \n",
    "\n",
    "\n",
    "Finally, we consider the confusion matrix of the both classifiers. First we notice that all the correctly classified instances appear on the diagonal of the matrix and all the instances that are wrongly classified not on the diagonal. \n",
    "\n",
    "If we look at the confusion matrix of the K-nn classifier, we notice that the only non-zero digits are on the diagonal. This again tells us that there are no false positives nor false negatives. \n",
    "\n",
    "If we look at the confusion matrix of the Logistic Regression classifier, we notice that here there are also non-zero digits not on the diagonal. This means that we indeed have wrongly classified instances.\n",
    "\n",
    "From our classification report, we suspected that there are relatively many 3's that are classified as 8's. If we look at position (9,4), we can see exactly how many 3's are being classified as 0's. We see that this number is 5, which is the biggest number not being on the diagonal, and we also notice that this is relatively big since we only have 30 actual instances of 3's. \n",
    "\n",
    "Moreover, we can read of the confusion matrix that \n",
    "- one 0 is being classified as a 4\n",
    "- three 1's are being classified as an 8\n",
    "- one 3 is being classified as a 1\n",
    "- two 3's are being classified as a 7\n",
    "- three 6's are being classified as a 9\n",
    "- one 5 is being classified as a 1\n",
    "- one 7 is being classified as a 1\n",
    "- two 7's are being classified as an 8\n",
    "- two 8's are being classified as a 1\n",
    "- two 9's are being classified as a 1\n",
    "- one 9 is being classified as a 3\n",
    "- one 9 is being classified as a 7\n",
    "- two 9's are being classified as an 8\n",
    "\n",
    "so if we sum up all these wrongly classified instances we get: 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BONUS: only continue with this part if you are confident that your implemention is complete\n",
    "- tune more parameters of logistic regression\n",
    "- add additional classifiers (NN, Naive Bayes, decision tree),\n",
    "- analyse additional dataset (ex. Iris dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus, Tune more parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intercept_scaling': 7.0099999999999998}\n",
      "{'max_iter': 7}\n"
     ]
    }
   ],
   "source": [
    "#here we search for the optimal values of two additional parameters, namely intercept_scaling and max_iter\n",
    "parametersLR_IS = {'intercept_scaling': np.arange(0.01, 10)}\n",
    "clf = GridSearchCV(LR, parametersLR_IS) \n",
    "clf.fit(X_train_mnist, y_train_mnist)\n",
    "print(clf.best_params_)\n",
    "\n",
    "parametersLR_MI = {'max_iter': np.arange(1, 100)}\n",
    "clf = GridSearchCV(LR, parametersLR_MI) \n",
    "clf.fit(X_train_mnist, y_train_mnist)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy under Logistic Regression with additional optimized parameters is:                    0.948869622252\n",
      "The standard deviation under Logistic Regression with additional optimized parameters is:                  0.0199466831998 \n",
      "\n",
      "The average accuracy under Logistic Regression with additional optimized parameters on the test set is:    0.924129001226\n",
      "The standard deviation under Logistic Regression with additional optimized parameters on the test set is:  0.0454692980345 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train the new optimum for logistic regression with the additional optimal parameters\n",
    "LR_opt = LogisticRegression(C=0.1, intercept_scaling= 7.009999, max_iter=7)\n",
    "LR_opt.fit(X_train_mnist, y_train_mnist)\n",
    "\n",
    "\n",
    "print(\"The average accuracy under Logistic Regression with additional optimized parameters is:                   \", \n",
    "      av_accuracy(LR_opt, X_train_mnist, y_train_mnist))\n",
    "print(\"The standard deviation under Logistic Regression with additional optimized parameters is:                 \", \n",
    "      standarddev(LR_opt, X_train_mnist, y_train_mnist),\n",
    "     \"\\n\")\n",
    "\n",
    "print(\"The average accuracy under Logistic Regression with additional optimized parameters on the test set is:   \", \n",
    "      av_accuracy(LR_opt, X_test_mnist, y_test_mnist))\n",
    "print(\"The standard deviation under Logistic Regression with additional optimized parameters on the test set is: \", \n",
    "      standarddev(LR_opt, X_test_mnist, y_test_mnist),\n",
    "     \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEXCAYAAACH/8KRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1150d5a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEXCAYAAAC+mHPKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHsRJREFUeJzt3XuYHVW55/HvjwSEhEhAWpRc8ZyIRM4xaIuoHAQRjRdO\n1NEHMIqgmIkDyPE5XpCcC6NGcZzxyAx4MIOISgMqEI3KEEAUBC+kI4FcIBJDyAWBRkAuUSDknT/W\naqg0u7tXx67end6/z/PsZ1etWlX11t7d9e5aa+9aigjMzMz6s1OzAzAzsx2DE4aZmRVxwjAzsyJO\nGGZmVsQJw8zMijhhmJlZESeMFibpcEkba9z+zyWdlKdnS7q6suz1ku6U9Jikd0raR9INkh6V9L/q\niqkZJK2T9KYh3udHJd2XX98XDOW+6yDpDEnnNzuOVje62QHYjkHShcDGiPiX7Vk/IjqAjkrRZ4Fz\nIuLsvP1/BR4Anh9D/OMgSVOBu4CdI2LLUO67DpJ2Br4CHBIRtzY7nsEQEV/onh5p79eOxFcY1ixT\ngJU95ldtT7KQ5A8+29oH2JVtX98iSkb0ecF/L9tvRP9h2DPNIZ+RtErSQ5K+KWnXXuoekJuRHpa0\nUtI/5vI5wGzgU7mJ40e9rH+UpDsk/UnSOYAqy06QdGOe/j3wEuBHeXuXAB+sbP9NknaSdLqk30v6\no6TvSdorrz9VUkj6sKT1wHW5/BBJv8zx3yrp8Mr+fy7pc5Juys1eV0vaOy++IT8/nPf/2h7Hta+k\nP3fvP5cdJOkBSTtL+htJ1+U4H5DUIWl8L6/RhZI+X5nfplkw7+tySV2S7pL0scqygyV1SnokNzd9\npcH2XwqsrhxP92vzOklL8nuzRNLrerw28yXdBGzO703P7a6T9ElJt0l6XNI3cjPi/8uv57WS9qzU\n/76ke/P+bpD08ly+i6Rlkk7N86Pye/JvjV6vyvbOlHRRnm34fkn6kKTb89/5YklTKuuHpJMl3Qnc\n2de+rA8R4ccIfgDrgBXAJGAv4Cbg83nZ4aRmJoCdgTXAGcAuwBuBR4H98/ILu9frZT975/rvydv6\nOLAFOCkvPwG4sUdcb6rMb7N94DTg18BE4HnA14FL8rKpQADfBsYCuwETgD8CbyN9EDoqz7fldX4O\n/B54aa7/c+CsHtsb3cfxXQd8pDL/ZeC8PP23eX/PA9pIJ7SvNjrWBsdZfQ92ApYC/5bfg5cAa4G3\n5OW/Aj6Qp3cnNTk1inWb48nv+0PAB0jN0Mfl+RdUXpv1wMvz8p17+Tv6NenqZQJwP/Bb4CDS1cx1\nwL9X6n8IGJdfk68CyyrLDsz7PwCYl7c7qp+/4zOBi3p7v4BZpL/fA/Ix/Avwy8ryAK7Jr8Vuzf6/\n3FEfvsJoDedExIaIeBCYTzph9HQI6SR0VkQ8GRHXAT/upW4jbwNWRsRlEfEU6SRx718R81xgXkRs\njIgnSCeM9/RoTjgzIh6PiD8D7weujIgrI2JrRFwDdOa4un0zIn6X638PmDGAeC4mvxaSBByby4iI\nNRFxTUQ8ERFdpP6DN2zHMb+alOA+m9+DtcD/zfsCeAr4W0l7R8RjEfHrwu2+HbgzIr4TEVsi4hLg\nDuDoSp0LI2JlXv5UL9v5PxFxX0RsAn4B/CYibomIvwALSckDgIi4ICIerbx3r5C0R162Avg88APg\nE6Qk+HThsfRmLvDFiLg9Ur/GF4AZ1auMvPzB/P7bdnDCaA0bKtN3A/s2qLMvsCEitvaoO6FwH/tW\n9xPpY92G3qv3awqwMDcvPQzcDjxN+oTbbUOP+u/trp/XORR4caVONYFtJiXIUpcDr5X0YuAwYCvp\npElumrlU0iZJjwAXka64BmoKsG+PYziDZ4/5w6QrpDtys9I7Cre7L+m9rOr53pa8V/dVpv/cYH53\neKaZ6azcnPgI6eoEtn1NvkU63isjYjCaiKYAZ1detwdJTaIDPUbrgzt/WsOkyvRk4J4Gde4BJkna\nqZI0JgO/y9P9dUb/obqf/Cl8Uu/V+7UB+FBE3NRzgdK3ZHrGtAH4TkR8ZDv21W9He0Q8pPS14GNI\nzR6X5qQI6dNsAH8XEQ9KeidwTi+behwYU5l/UWV6A3BXREzrJYY7geOUOqXfDVwm6QUR8Xg/4d9D\nOqFWTQauqm6+n20MxPtITURvIiWLPUhNUKrU+RrpCvYtkg6NiBsHsP1GsW4A5kf6Nt5A1rMB8BVG\nazhZ0sTcaTsP+G6DOr8hfer+VO7IPZzUZHFpXn4fDTpDK34CvFzSu3Oz0cfY9mQ4UOcB87ubFCS1\nSZrVR/2LgKMlvSV/wt01dyhPLNhXF+mKoa/jg9QEdTypn+biSvk44DHgT5ImAJ/sYxvLgLdJ2kvS\ni4B/qiy7GXhU0qcl7ZaP40BJrwaQ9H5JbTmhP5zX2Ur/rgReKul9kkZLOgaYTjph12Ec8ASpD2kM\nKaE+Q9IHgFeR+rU+BnxL0kCu9hq9X+cBn6l0ru8h6b3bewDWmBNGa7gYuJrUgfp7UvvxNiLiSVKC\neCvp9xBfA46PiDtylW8A0/Ml/w8arP8A8F7gLNKJYhqpg317nQ0sAq6W9CipY/Q1vVWOiA2kT7Vn\nkE4oG0gn7n7/xiNiM6lv56Z8fIf0UnUR6bjujW1/3/DfgVcCfyIlziv62N13gFtJn7yvppK8czv+\nO0h9K3eR3ofzSZ/QAWYCKyU9Rnp9ji1pj4+IP+bt/jPpvfkU8I78ntXh26Qmr03AKtJ7B4CkyaT+\nreNzP8zFpL6m/yjdeKP3KyIWAl8CLs3NYCtIf8s2iPTsVbWNRJLWkb6pdG2zYzGzHZuvMMzMrIgT\nhpkNC/lHgI81eJzR7NgscZOUmZkV8RWGmZkVGVG/w9h7771j6tSpzQ7DzGyHsXTp0gcioq2k7ohK\nGFOnTqWzs7PZYZiZ7TAk9bwLQK/cJGVmZkWcMMzMrIgThpmZFXHCMDOzIk4YZmZWxAnDzEaGjg6Y\nOhV22ik9d/R1p3PbHrUmDEkzJa2WtEbS6Q2W7ylpYR4n+GZJB1aWrZO0PI//6+/Kmg1Eq508Ozpg\nzhy4+26ISM9z5oz84x5itSUMSaOAc0m3GJ5OGvhleo9qZ5DG+v170jgDZ/dYfkREzIiI9rriNBtx\nWvHkOW8ebN68bdnmzancBk2dVxgHA2siYm0ea+FS0ngFVdNJg8eTx12YKmkfzGz7teLJc/36gZXb\ndqkzYUxg2zF0N/Lc8aFvJQ01iaSDScNIdo+QFsC1kpZKmtPbTiTNkdQpqbOrq2vQgjfbYbXiyXPy\n5IGV23Zpdqf3WcB4ScuAU4FbgKfzskMjYgapSetkSYc12kBELIiI9ohob2sruh2K2cjWiifP+fNh\nzJhty8aMSeUj2RD3VdWZMDYBkyrzE3PZMyLikYg4MSeG44E20jCiRMSm/Hw/sJDUxGVm/WnFk+fs\n2bBgAUyZAlJ6XrAglY9UTeirqjNhLAGmSdpP0i7AsaQxkZ8haXxeBnAScENEPCJprKRxuc5Y4M2k\nMXrNrD+tePKEdHzr1sHWrel5pB9vE/qqaksYEbEFOAVYDNwOfC8iVkqaK2lurnYAsELSalLT02m5\nfB/gRkm3AjcDP4mIq+qK1VpAq33NtNVOnq2oCX1Vtd7ePCKuBK7sUXZeZfpXwEsbrLcWeEWdsVkL\n6b507/401n3pDj6R2o5r8uT0t9yovCbN7vQ2q18rfs3URr4m9FU5YdjI14pfM7WRrwl9VSNqxD2z\nhppw6W42JGbPHtJmVV9h2MjXil8zNauBE4aNfK36NVOzQeYmKWsNQ3zpbjYS+QrDzMyKOGGYmVkR\nJwwzMyvihGFmZkWcMMzMrIgThpmZFXHCMDOzIk4YZmZWxAnDzMyKOGGYmVkRJwwzMyvihGFmZkWc\nMMzMrIgThpmZFXHCMDOzIk4YZmZWxAnDzMyK1JowJM2UtFrSGkmnN1i+p6SFkm6TdLOkA0vXNTOz\noVVbwpA0CjgXeCswHThO0vQe1c4AlkXE3wPHA2cPYF0zMxtCdV5hHAysiYi1EfEkcCkwq0ed6cB1\nABFxBzBV0j6F65qZ2RCqM2FMADZU5jfmsqpbgXcDSDoYmAJMLFyXvN4cSZ2SOru6ugYpdDMz66nZ\nnd5nAeMlLQNOBW4Bnh7IBiJiQUS0R0R7W1tbHTGamRkwusZtbwImVeYn5rJnRMQjwIkAkgTcBawF\ndutvXTMzG1p1XmEsAaZJ2k/SLsCxwKJqBUnj8zKAk4AbchLpd10zMxtatV1hRMQWSacAi4FRwAUR\nsVLS3Lz8POAA4FuSAlgJfLivdeuK1czM+qeIaHYMg6a9vT06OzubHcbw19EB8+bB+vUweTLMnw+z\nZzc7KjNrAklLI6K9pG6dfRg2HHV0wJw5sHlzmr/77jQPThpm1qdmf0vKhtq8ec8mi26bN6dyM7M+\nOGG0mvXrB1ZuZpY5YbSayZMHVm5mljlhtJr582HMmG3LxoxJ5WZmfXDCaDWzZ8OCBTBlCkjpecEC\nd3ibWb/8LalWNHu2E4SZDZivMMzMrIgThpmZFXHCMDOzIk4YZmZWxAnDzMyKOGGYmVkRJwwzMyvi\nhGFmZkWcMMzMrIgThpmZFXHCMDOzIk4YZmZWxAnDzMyKOGGYmVkRJwwzMyvihGFmZkVqTRiSZkpa\nLWmNpNMbLN9D0o8k3SpppaQTK8vWSVouaZmkzjrjNDOz/tU24p6kUcC5wFHARmCJpEURsapS7WRg\nVUQcLakNWC2pIyKezMuPiIgH6orRzMzK1XmFcTCwJiLW5gRwKTCrR50AxkkSsDvwILClxpjMzGw7\n1ZkwJgAbKvMbc1nVOcABwD3AcuC0iNialwVwraSlkub0thNJcyR1Surs6uoavOjNzGwbze70fguw\nDNgXmAGcI+n5edmhETEDeCtwsqTDGm0gIhZERHtEtLe1tQ1J0GZmrajOhLEJmFSZn5jLqk4Erohk\nDXAX8DKAiNiUn+8HFpKauMzMrEnqTBhLgGmS9pO0C3AssKhHnfXAkQCS9gH2B9ZKGitpXC4fC7wZ\nWFFjrGZm1o/aviUVEVsknQIsBkYBF0TESklz8/LzgM8BF0paDgj4dEQ8IOklwMLUF85o4OKIuKqu\nWM3MrH+KiGbHMGja29ujs9M/2TAzKyVpaUS0l9Rtdqe3mZntIJwwzMysiBOGmZkVccIwM7MiThhm\nZlbECcPMzIo4YZiZWREnDDMzK1KUMCRdIentkpxgzMxaVGkC+BrwPuBOSWdJ2r/GmMzMbBgqShgR\ncW1EzAZeCawjjVPxS0knStq5zgDNzGx4KG5ikvQC4ATgJOAW4GxSArmmlsjMzGxYKbpbraSFpFuP\nfwc4OiL+kBd9V5Lv9mdm1gJKb2/+vyPiZ40WlN7l0MzMdmylTVLTJY3vnpG0p6T/VlNMZmY2DJUm\njI9ExMPdMxHxEPCRekIyM7PhqDRhjFIe/g5A0ihgl3pCMjOz4ai0D+MqUgf31/P8f81lZmbWIkoT\nxqdJSeKjef4a4PxaIjIzs2GpKGFExFbgP/PDzMxaUOnvMKYBXwSmA7t2l0fES2qKy8zMhpnSTu9v\nkq4utgBHAN8GLqorKDMzG35KE8ZuEfFTQBFxd0ScCby9v5UkzZS0WtIaSac3WL6HpB9JulXSSkkn\nlq5rZmZDq7TT+4l8a/M7JZ0CbAJ272uF/NXbc4GjgI3AEkmLImJVpdrJwKqIOFpSG7BaUgfwdMG6\nZmY2hEqvME4DxgAfA14FvB/4YD/rHAysiYi1EfEkcCkwq0edAMbl33jsDjxIavYqWdfMzIZQv1cY\n+UrhmIj4BPAYcGI/q3SbAGyozG8EXtOjzjnAIuAeYFzez1ZJJeuamdkQ6vcKIyKeBg6taf9vAZYB\n+wIzgHMkPX8gG5A0R1KnpM6urq46YjQzM8r7MG6RtAj4PvB4d2FEXNHHOpuASZX5ibms6kTgrIgI\nYI2ku4CXFa7bHcMCYAFAe3t7FB2NmZkNWGnC2BX4I/DGSlkAfSWMJcA0SfuRTvbHkoZ5rVoPHAn8\nQtI+pDE31gIPF6xrZmZDqPSX3qX9FtV1tuRvVC0GRgEXRMRKSXPz8vOAzwEXSloOCPh0RDwA0Gjd\ngcZgZmaDR6k1qJ9K0jdJVxTbiIgP1RHU9mpvb4/OTg8AaGZWStLS0oHwSpukflyZ3hV4F+mbTWZm\n1iJKm6Qur85LugS4sZaIzMxsWCr94V5P04AXDmYgZmY2vJXerfZRtu3DuJc0RoaZmbWI0iapcXUH\nYmZmw1tRk5Skd0naozI/XtI76wvLzMyGm9I+jH+PiD91z0TEw8C/1xOSmZkNR6UJo1G90q/kmpnZ\nCFCaMDolfUXS3+THV4CldQZmZmbDS2nCOBV4EvguaWyKv5AGPzIzsxZR+i2pxwEPk2pm1sJKvyV1\njaTxlfk9JS2uLywzMxtuSpuk9s7fjAIgIh7Cv/Q2M2sppQljq6TJ3TOSptLg7rVmZjZylX41dh5w\no6TrSeNW/AMwp7aozMxs2Cnt9L5KUjspSdwC/AD4c52BmZnZ8FJ688GTgNNIY2svAw4BfsW2Q7aa\nmdkIVtqHcRrwauDuiDgCOIg07raZmbWI0oTxl4j4C4Ck50XEHcD+9YVlZmbDTWmn98b8O4wfANdI\negi4u76wzMxsuCnt9H5XnjxT0s+APYCraovKzMyGnQHfcTYirq8jEDMzG962d0xvMzNrMbUmDEkz\nJa2WtEbSc25eKOmTkpblxwpJT0vaKy9bJ2l5XtZZZ5xmZta/2gZBkjQKOBc4CtgILJG0KCJWddeJ\niC8DX871jwY+HhEPVjZzREQ8UFeMZmZWrs4rjIOBNRGxNiKeJI2jMauP+scBl9QYj5mZ/RXqTBgT\ngA2V+Y257DkkjQFmApdXigO4VtJSSb3et0rSHEmdkjq7uroGIWwzM2tkuHR6Hw3c1KM56tCImAG8\nFThZ0mGNVoyIBRHRHhHtbW1tQxGrmVlLqjNhbAImVeYn5rJGjqVHc1REbMrP9wMLSU1cZmbWJHUm\njCXANEn7SdqFlBQW9awkaQ/gDcAPK2VjJY3rngbeDKyoMVYzM+tHbd+Siogtkk4BFgOjgAsiYqWk\nuXn5ebnqu4Cr87jh3fYBFkrqjvHiiPAvy83MmkgRI2fgvPb29ujs9E82zMxKSVoaEe0ldYdLp7eZ\nmQ1zThhmZlbECcPMzIo4YZiZWREnDDMzK+KEYWZmRZwwzMysiBOGmZkVccIwM7MiThhmZlbECcPM\nzIo4YZiZWREnDDMzK+KEYWZmRZwwzMysiBOGmZkVccIwM7MiThhmZlbECcPMzIo4YZiZWREnDDMz\nK+KEYWZmRZwwzMysSK0JQ9JMSaslrZF0eoPln5S0LD9WSHpa0l4l65qZ2dCqLWFIGgWcC7wVmA4c\nJ2l6tU5EfDkiZkTEDOAzwPUR8WDJumZmNrTqvMI4GFgTEWsj4kngUmBWH/WPAy7ZznXNzKxmdSaM\nCcCGyvzGXPYcksYAM4HLt2PdOZI6JXV2dXX91UGbmVljw6XT+2jgpoh4cKArRsSCiGiPiPa2trYa\nQjMzM6g3YWwCJlXmJ+ayRo7l2eaoga5rZmZDoM6EsQSYJmk/SbuQksKinpUk7QG8AfjhQNc1M7Oh\nM7quDUfEFkmnAIuBUcAFEbFS0ty8/Lxc9V3A1RHxeH/r1hWrmZn1TxHR7BgGTXt7e3R2djY7DDOz\nHYakpRHRXlJ3uHR6m5nZMOeEYWZmRZwwzMysiBOGmZkVccIwM7MiThhmZlbECcPMzIo4YZiZWREn\nDDMzK+KEYWZmRZwwzMysiBOGmZkVccIwM7MiThhmZlbECcPMzIo4YZiZWREnDDMzK+KEYWZmRZww\nzMysiBOGmZkVccIwM7MiThhmZlak1oQhaaak1ZLWSDq9lzqHS1omaaWk6yvl6yQtz8s664zTzMz6\nN7quDUsaBZwLHAVsBJZIWhQRqyp1xgNfA2ZGxHpJL+yxmSMi4oG6YjQzs3J1XmEcDKyJiLUR8SRw\nKTCrR533AVdExHqAiLi/xnjMzOyvUGfCmABsqMxvzGVVLwX2lPRzSUslHV9ZFsC1uXxOjXGamVmB\n2pqkBrD/VwFHArsBv5L064j4HXBoRGzKzVTXSLojIm7ouYGcTOYATJ48eQhDNzNrLXVeYWwCJlXm\nJ+ayqo3A4oh4PPdV3AC8AiAiNuXn+4GFpCau54iIBRHRHhHtbW1tg3wIZmbWrc6EsQSYJmk/SbsA\nxwKLetT5IXCopNGSxgCvAW6XNFbSOABJY4E3AytqjNXMzPpRW8KIiC3AKcBi4HbgexGxUtJcSXNz\nnduBq4DbgJuB8yNiBbAPcKOkW3P5TyLiqloC7eiAqVNhp53Sc0dHLbsxM9vRKSKaHcOgaW9vj87O\nAfxko6MD5syBzZufLRszBhYsgNmzBz9AM7NhRtLSiGgvqdvav/SeN2/bZAFpft685sRjZjaMtXbC\nWL9+YOVmZi2stRNGb1/D9ddzzcyeo7UTxvz5qc+iasyYVG5mZtto7YQxe3bq4J4yBaT07A5vM7OG\nmv1L7+abPdsJwsysQGtfYZiZWTEnDDMzK+KEYWZmRZwwzMysiBOGmZkVGVH3kpLUBdzd7DgGaG+g\n1Yah9TG3Bh/zjmFKRBSNDTGiEsaOSFJn6Y2/Rgofc2vwMY88bpIyM7MiThhmZlbECaP5FjQ7gCbw\nMbcGH/MI4z4MMzMr4isMMzMr4oRhZmZFnDCaRNIkST+TtErSSkmnNTumoSBplKRbJP242bEMFUnj\nJV0m6Q5Jt0t6bbNjqpOkj+e/6RWSLpG0a7NjGmySLpB0v6QVlbK9JF0j6c78vGczY6yDE0bzbAH+\nOSKmA4cAJ0ua3uSYhsJpwO3NDmKInQ1cFREvA17BCD5+SROAjwHtEXEgMAo4trlR1eJCYGaPstOB\nn0bENOCneX5EccJokoj4Q0T8Nk8/SjqJTGhuVPWSNBF4O3B+s2MZKpL2AA4DvgEQEU9GxMPNjap2\no4HdJI0GxgD3NDmeQRcRNwAP9iieBXwrT38LeOeQBjUEnDCGAUlTgYOA3zQ3ktp9FfgUsLXZgQyh\n/YAu4Ju5Ke58SWObHVRdImIT8D+B9cAfgD9FxNXNjWrI7BMRf8jT9wL7NDOYOjhhNJmk3YHLgX+K\niEeaHU9dJL0DuD8iljY7liE2Gngl8J8RcRDwOCOwqaJbbrefRUqU+wJjJb2/uVENvUi/Vxhxv1lw\nwmgiSTuTkkVHRFzR7Hhq9nrgHyWtAy4F3ijpouaGNCQ2Ahsjovvq8TJSAhmp3gTcFRFdEfEUcAXw\nuibHNFTuk/RigPx8f5PjGXROGE0iSaR27dsj4ivNjqduEfGZiJgYEVNJnaDXRcSI/+QZEfcCGyTt\nn4uOBFY1MaS6rQcOkTQm/40fyQju5O9hEfDBPP1B4IdNjKUWThjN83rgA6RP2svy423NDspqcSrQ\nIek2YAbwhSbHU5t8JXUZ8FtgOekcM+JulyHpEuBXwP6SNkr6MHAWcJSkO0lXWmc1M8Y6+NYgZmZW\nxFcYZmZWxAnDzMyKOGGYmVkRJwwzMyvihGFmZkWcMMzMrIgThrUUSY/VvP02Sb/J9436hzr31UcM\n+0q6LE/P8O97bLA4YZgNriOB5RFxUET8ohkBRMQ9EfGePDsDGFDCyHeZNXsOJwzbYUk6S9LJlfkz\nJX1C0u6Sfirpt5KWS5rVYN3Dq4M4STpH0gl5+lWSrpe0VNLi7vsD9Vh/qqTrJN2W9zVZ0gzgfwCz\n8i/3d+uxzjpJX8zLOiW9Mm//95Lm5joNY5f06ryvXSWNzQMUHdjL6zI1D160C/BZ4Ji8z2PyuhdI\nujlfBXVv/wRJiyRdRxrLwey5IsIPP3bIB+mW8NdX5lcBk0h3iH1+LtsbWMOzdzV4LD8fDvy4su45\nwAnAzsAvgbZcfgxwQYN9/wj4YJ7+EPCDPH0CcE4v8a4DPpqn/wO4DRgHtAH35fK+Yv886dbh5wKf\n6eN1mQqsaBQP6bYk78/T44HfAWNzvY3AXs1+X/0Yvg9fetoOKyJukfRCSfuSTroPRcSGfBfgL0g6\njDT2xgTS2AT3Fmx2f+BA4Jp07zxGkcZ16Om1wLvz9HdIVxYlFuXn5cDukQbPelTSE5LGk25/3lvs\nnwWWAH8hjWq3Pd5MumvwJ/L8rsDkPH1NRPQcFMjsGU4YtqP7PvAe4EXAd3PZbFICeVVEPJVvqd5z\nXOktbNsk271cwMqIqGvc7Sfy89bKdPf8aPqO/QXA7qSroF1JyWWgBPyXiFi9TaH0mu3cnrUQ92HY\nju67pNulv4eUPAD2IA3W9JSkI4ApDda7G5gu6Xn5k/2RuXw10CbptZDGLJH08gbr/5Jnx6qeDQxW\nB3dfsX8d+FegA/hS4fYeJTV7dVsMnJpvPY6kg/76kK1VOGHYDi0iVpJOiJvi2eExO4B2ScuB44E7\nGqy3AfgesCI/35LLnyQlny9JuhVYRuMBgE4FTsy3LP8AcNogHVLD2CUdDzwVEReTbpv9aklvLNje\nz0iJcZmkY4DPka5QbpO0Ms+bFfHtzc3MrIivMMzMrIg7vc12UJL+jvQNraonIuI1zYjHRj43SZmZ\nWRE3SZmZWREnDDMzK+KEYWZmRZwwzMysyP8HtIGSDz9J/c0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1136d2a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot a graph for multiple values of intercept_scaling\n",
    "def gpLRIC(X):\n",
    "    LRIC = LogisticRegression(intercept_scaling= X)\n",
    "    LRIC.fit(X_train_mnist, y_train_mnist)\n",
    "    return LRIC\n",
    "\n",
    "plt.plot([1, 3, 5, 7, 9, 11], [av_accuracy(gpLRIC(1),X_train_mnist, y_train_mnist), av_accuracy(gpLRIC(3), X_train_mnist, y_train_mnist), av_accuracy(gpLRIC(5), X_train_mnist, y_train_mnist), av_accuracy(gpLRIC(7), X_train_mnist, y_train_mnist), av_accuracy(gpLRIC(9), X_train_mnist, y_train_mnist), av_accuracy(gpLRIC(11), X_train_mnist, y_train_mnist)], \"ro\")\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('value of intercept_scaling')\n",
    "plt.title('plot different values for intercept_scaling')\n",
    "plt.show()\n",
    "\n",
    "#plot a graph for multiple values of max_iter\n",
    "def gpLRMI(X):\n",
    "    LRMI = LogisticRegression(max_iter=X)\n",
    "    LRMI.fit(X_train_mnist, y_train_mnist)\n",
    "    return LRMI\n",
    "\n",
    "plt.plot([1, 3, 5, 7, 9, 11], [av_accuracy(gpLRMI(1),X_train_mnist, y_train_mnist), av_accuracy(gpLRMI(3), X_train_mnist, y_train_mnist), av_accuracy(gpLRMI(5), X_train_mnist, y_train_mnist), av_accuracy(gpLRMI(7), X_train_mnist, y_train_mnist), av_accuracy(gpLRMI(9), X_train_mnist, y_train_mnist), av_accuracy(gpLRMI(11), X_train_mnist, y_train_mnist)], \"ro\")\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('value of max_iter')\n",
    "plt.title('plot different values for max_iter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus, analysis extra parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We thus see that the accuracy gets higher as the value of intercept_scaling gets higher. Moreover, we see that for low values of max_iter is the accuracy is low. Then it reaches a peak at 7 iterations and then it goes down very slowly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus, Additional Classifier Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9}\n",
      "{'min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clfDT = tree.DecisionTreeClassifier()\n",
    "clfDT.fit(X_train_mnist, y_train_mnist)\n",
    "\n",
    "#search for the best value of max_depth\n",
    "parametersDT_MD = {'max_depth': np.arange(1, 10)}\n",
    "clf = GridSearchCV(clfDT, parametersDT_MD) \n",
    "clf.fit(X_train_mnist, y_train_mnist)\n",
    "print(clf.best_params_)\n",
    "\n",
    "#search for the best value of min_samples_split\n",
    "parametersDT_MSS = {'min_samples_split': np.arange(2, 10)}\n",
    "clf = GridSearchCV(clfDT, parametersDT_MSS) \n",
    "clf.fit(X_train_mnist, y_train_mnist)\n",
    "print(clf.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy under Logistic Regression with additional optimized parameters is:                    0.82309722829\n",
      "The standard deviation under Logistic Regression with additional optimized parameters is:                  0.0477538623817 \n",
      "\n",
      "The average accuracy under Logistic Regression with additional optimized parameters on the test set is:    0.760887290726\n",
      "The standard deviation under Logistic Regression with additional optimized parameters on the test set is:  0.065761804585 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train the decision tree classifier on the found optimal values for the parameters on the trian set\n",
    "clfDT_opt = tree.DecisionTreeClassifier(max_depth=9, min_samples_split=2)\n",
    "clfDT_opt.fit(X_train_mnist, y_train_mnist)\n",
    "\n",
    "#print the accuracies and standard deviation using 10-fold-crossvalidation on the training and test set\n",
    "print(\"The average accuracy under Logistic Regression with additional optimized parameters is:                   \", \n",
    "      av_accuracy(clfDT_opt, X_train_mnist, y_train_mnist))\n",
    "print(\"The standard deviation under Logistic Regression with additional optimized parameters is:                 \", \n",
    "      standarddev(clfDT_opt, X_train_mnist, y_train_mnist),\n",
    "     \"\\n\")\n",
    "\n",
    "print(\"The average accuracy under Logistic Regression with additional optimized parameters on the test set is:   \", \n",
    "      av_accuracy(clfDT_opt, X_test_mnist, y_test_mnist))\n",
    "print(\"The standard deviation under Logistic Regression with additional optimized parameters on the test set is: \", \n",
    "      standarddev(clfDT_opt, X_test_mnist, y_test_mnist),\n",
    "     \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEXCAYAAABCjVgAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHjxJREFUeJzt3XuYHHWd7/H3JxMQRxCQjBdyG9SARl1ABkRlMahoRN2I\nhz0ERhBRc+IRRB9R0Zz14CXKnj3LqgcUZxFRHAkIiMFluSgCCurJBCKQABJDrggMAYQQbjHf/aN+\nU6lpe2Z6wlT3TM/n9TzzdNevfl31re6e/nRdukoRgZmZGcCERhdgZmajh0PBzMxyDgUzM8s5FMzM\nLOdQMDOznEPBzMxyDoUmIGmWpPUlTv96SR9J9zslXVMY92ZJ90jaJOl9kl4i6UZJj0v617JqagRJ\nqyW9vc7z/JikB9Lzu0c9510PZb53JbVLCkkTy5h+s3IojDOSzpf01e19fER0R8Q7Ck1fBs6KiJ0j\n4nJgHvAQ8MKI+PRzLHdYmu1DQNIOwJnAO9Lzu7HRNY1mjQjtZuRQsOdqOrC8YnhFbMevIpvlw3wE\nvQTYif7Pb02U8f+3DZvfNGNE+hb0eUkrJD0i6fuSdhqg76vTJp9HJS2X9A+pfR7QCXw2bY64YoDH\nHy7pLkl/kXQWoMK4EyT9Jt3/E/By4Io0vQuBDxam/3ZJEySdJulPkjZKuljSi9Lj+77Zf1jSWuC6\n1H6wpJtT/X+QNKsw/+slfUXSTWkT1TWSJqXRN6bbR9P831ixXHtKerJv/qltf0kPSdpB0iskXZfq\nfEhSt6TdBniO+q1xVW4GSfO6VFKvpHslfaIw7iBJPZIeS5uGzqwy/b2BuwvL0/fcvEnSkvTaLJH0\npornZqGkm4DN6bWpnO5qSZ+RdJukJyR9L23y+8/0fP5C0u6F/j+RdH+a342SXpPad5S0TNLJabgl\nvSZfrPZ8Fab3/PTcPSJpBXBgxfjBnrfTJV0i6aJU6y2S9k3jLgCmse29+NnCZDslrU2v6YLB6jMg\nIvw3Bv6A1cAdwFTgRcBNwFfTuFnA+nR/B2Al8AVgR+CtwOPAPmn8+X2PG2A+k1L/o9K0PgVsAT6S\nxp8A/KairrcXhvtNHzgF+B0wBXge8F3gwjSuHQjgh8ALgOcDk4GNwBFkX1oOT8Nt6THXA38C9k79\nrwfOqJjexEGW7zrgo4XhfwHOSfdfmeb3PKCNLGS+UW1Zqyxn8TWYACwFvpheg5cDq4B3pvG/BY5L\n93cGDh6g1n7Lk173R4DjgInAMWl4j8JzsxZ4TRq/wwDvo9+RrYVMBh4EbgH2J1sruQ7434X+JwK7\npOfkG8CywrjXpvm/GliQptsyxPv4DODXaVmmkr2na33eTgeeZdt781Tg3r7l5G/fi33P37+n98q+\nwNPAqxv9/zya/7ymMLacFRHrIuJhYCHZh0Klg8k+aM6IiGci4jrg5wP0reYIYHlEXBIRz5J9ENz/\nHGqeDyyIiPUR8TTZP/ZR6r+p6PSIeCIingQ+AFwZEVdGxNaIuBboSXX1+X5E/DH1vxjYbxj1/Jj0\nXEgSMDe1ERErI+LaiHg6InrJtue/ZTuW+UCyEPtyeg1WkX0wzU3jnwVeKWlSRGyKiN/VON13A/dE\nxAURsSUiLgTuAt5b6HN+RCxP458dYDr/LyIeiIgNZB/Qv4+IWyPiKeCnZAEBQEScFxGPF167fSXt\nmsbdAXwVuJzsA/q4iPjrEMvw34GFEfFwRKwDvlUYN9TzBrC08N48kyzIDh5inl+KiCcj4g/AH8jC\nwQbgUBhb1hXurwH2rNJnT2BdRGyt6Du5xnnsWZxPZF+51g3cfUjTgZ+mTUGPAncCfyX7ptpnXUX/\nf+zrnx5zCPCyQp9iSG0mC8FaXQq8UdLLgEOBrWQfjKTNKIskbZD0GPAjsjWn4ZoO7FmxDF9g2zJ/\nmGxN5660Ceg9NU53T7LXsqjyta3ltXqgcP/JKsM7Q75J6Iy06e8xsm/i0P85+QHZ8l4ZEffUMO9+\n7y/6L89Qzxv0f29uBdZT/f+g6Lm8X8Yd79gbW6YW7k8D7qvS5z5gqqQJhWCYBvwx3R9qB/Cfi/NJ\n36anDtx9SOuAEyPipsoRktqr1LQOuCAiProd8xpy53ZEPKLskNqjyTZ7LErBB/C1NI3XRcTDkt4H\nnDXApJ4AWgvDLy3cXwfcGxEzBqjhHuAYZTuC3w9cImmPiHhiiPLvI/vgLJoGXFWc/BDTGI5jgTnA\n28kCYVeyzUUq9Pk22ZroOyUdEhG/GWKafe+vvp3n0wrjBn3ekuJ7cwLZZsm+/wOf8nkEeE1hbPm4\npClpR+kC4KIqfX5P9m3os2nn6SyyzQuL0vgHqLIDsuA/gNdIen/axPMJ+n/gDdc5wEJJ0wEktUma\nM0j/HwHvlfTO9E11p7QTd0oN8+ol++Y/2PJBtrnoeLJt0z8utO8CbAL+Imky8JlBprEMOELSiyS9\nFPhkYdz/Bx6X9Lm0Y7VF0mslHQgg6QOS2lJoP5oes5WhXQnsLelYSRMlHQ3MJPtQLsMuZNvgN5IF\n4NeKIyUdBxxAtp/pE8APJA31Lfxi4POSdk+v6cmFcYM+b8kBhffmJ1N9fZvfhnpvWw0cCmPLj4Fr\nyHa+/Ylse24/EfEMWQi8i+z3At8Gjo+Iu1KX7wEz0+r55VUe/xDwj2Q7BDcCM8h2am+vbwKLgWsk\nPU72D/yGgTqn7cxzyDYb9JJ9e/wMNbxXI2Iz2b6Wm9LyDbSteTHZct2ftjP3+RLweuAvZOF42SCz\nu4Bs+/RqstckD+i0Xf09ZPs67iV7Hc4l+6YNMBtYLmkT2fMzN+0fGWr5Nqbpfprstfks8J70mpXh\nh2SbdzYAK9j24YukaWT7m45P+0V+TLbv59+GmOaX0jTvJXveLugbUcPzBvAzsrW8vh3u7y/sO/k6\n8L/Sa3/q9iywgbatOdtoJmk12RFAv2h0LWaNIOl04JUR8YFG19LMvKZgZmY5h4KZjaj0Q7hNVf6+\n0OjabGjefGRmZjmvKZiZWW7M/U5h0qRJ0d7e3ugyzMzGlKVLlz4UEW1D9RtzodDe3k5PT0+jyzAz\nG1MkVf4avipvPjIzs5xDwczMcg4FMzPLORTMzCznUDAzs5xDwcxstOvuhvZ2mDAhu+3uLm1WY+6Q\nVDOzcaW7G+bNg82bs+E1a7JhgM7OEZ+d1xTMbGyp47fmUWHBgm2B0Gfz5qy9BF5TMLOxo87fmkeF\ntWuH1/4ceU3BzMaOOn9rHhWmTRte+3PkUDCzsaPO35pHhYULobW1f1tra9ZeAoeCmY0ddf7WPCp0\ndkJXF0yfDlJ229VV2uYyh4KZjR11/tY8anR2wurVsHVrdlvi/hOHgtlYNt6OxKnzt+bxqNRQkDRb\n0t2SVko6rcr4XSVdIekPkpZL+lCZ9Zg1lb4jcdasgYhtR+KMh2Co07fm8ai0UJDUApwNvAuYCRwj\naWZFt48DKyJiX2AW8K+SdiyrJrOmMh6PxLHSlbmmcBCwMiJWRcQzwCJgTkWfAHaRJGBn4GFgS4k1\nmTWP8XgkjpWuzFCYDKwrDK9PbUVnAa8G7gNuB06JiK0l1mTWPMbjkThWukbvaH4nsAzYE9gPOEvS\nCys7SZonqUdST29vb71rNBudxuuROFaqMkNhAzC1MDwltRV9CLgsMiuBe4FXVU4oIroioiMiOtra\nhrzutNn44CNxrARlnvtoCTBD0l5kYTAXOLaiz1rgbcCvJb0E2AdYVWJNZs2ls9MhYCOqtFCIiC2S\nTgKuBlqA8yJiuaT5afw5wFeA8yXdDgj4XEQ8VFZNZmY2uFLPkhoRVwJXVrSdU7h/H/COMmswM7Pa\nNXpHs5mZjSIOBTMzyzkUzMws51AwM7OcQ8HMzHIOBTMzyzkUzMws51AwM7OcQ8HMzHIOBTMzyzkU\nzMws51AwM7OcQ8HMzHIOBTMzyzkUzMws51AwM7OcQ8HMzHIOBTMzyzkUzMws51AwM7OcQ8HMzHIO\nBTMzyzkUzMwsV2ooSJot6W5JKyWdVmX8ZyQtS393SPqrpBeVWZOZmQ2stFCQ1AKcDbwLmAkcI2lm\nsU9E/EtE7BcR+wGfB26IiIfLqsnMzAZX5prCQcDKiFgVEc8Ai4A5g/Q/BriwxHrMzGwIZYbCZGBd\nYXh9avsbklqB2cClA4yfJ6lHUk9vb++IF2pmZpnRsqP5vcBNA206ioiuiOiIiI62trY6l2ZmNn6U\nGQobgKmF4SmprZq5eNORmVnDlRkKS4AZkvaStCPZB//iyk6SdgXeAvysxFrMzKwGE8uacERskXQS\ncDXQApwXEcslzU/jz0ldjwSuiYgnyqrFzMxqU+o+hYi4MiL2johXRMTC1HZOIRCIiPMjYm6Zddg4\n0d0N7e0wYUJ2293d6IrMxpzS1hTM6qq7G+bNg82bs+E1a7JhgM7OxtVlNsaMlqOPzJ6bBQu2BUKf\nzZuzdjOrmUPBmsPatcNrN7OqHArWHKZNG167mVXlULDmsHAhtLb2b2ttzdrNrGYOBWsOnZ3Q1QXT\np4OU3XZ1eSez2TD56CNrHp2dDgGz58hrCmZmlnMomJlZzqFgZmY5h4KZmeUcCmZmlnMomJlZzqFg\nZmY5h4KZmeUcCmZmlnMomJlZzqFgZmY5h4KZmeUcCmZmlnMomJlZzqFgZma5UkNB0mxJd0taKem0\nAfrMkrRM0nJJN5RZj5mZDa60i+xIagHOBg4H1gNLJC2OiBWFPrsB3wZmR8RaSS8uqx4zMxtamWsK\nBwErI2JVRDwDLALmVPQ5FrgsItYCRMSDJdZjZmZDKDMUJgPrCsPrU1vR3sDukq6XtFTS8dUmJGme\npB5JPb29vSWVa2Zmjd7RPBE4AHg38E7gnyTtXdkpIroioiMiOtra2updo5nZuFHaPgVgAzC1MDwl\ntRWtBzZGxBPAE5JuBPYF/lhiXWZmNoAy1xSWADMk7SVpR2AusLiiz8+AQyRNlNQKvAG4s8SazMxs\nEKWtKUTEFkknAVcDLcB5EbFc0vw0/pyIuFPSVcBtwFbg3Ii4o6yazMxscIqIRtcwLB0dHdHT09Po\nMszMxhRJSyOiY6h+jd7RbGZmo0hNoSDpMknvluQQMTNrYrV+yH+b7Idm90g6Q9I+JdZkZmYNUlMo\nRMQvIqITeD2wGviFpJslfUjSDmUWaGZm9VPz5iBJewAnAB8BbgW+SRYS15ZSmZmZ1V1Nh6RK+imw\nD3AB8N6I+HMadZEkHwpkZtYkav2dwrci4lfVRtRyiJOZmY0NtW4+mplOcw2ApN0l/c+SajIzswap\nNRQ+GhGP9g1ExCPAR8spyczMGqXWUGiRpL6BdAGdHcspyczMGqXWfQpXke1U/m4a/h+pzczMmkit\nofA5siD4WBq+Fji3lIrMzKxhagqFiNgKfCf9mZlZk6r1dwozgK8DM4Gd+toj4uUl1WVmZg1Q647m\n75OtJWwBDgN+CPyorKLMzKwxag2F50fEL8muv7AmIk4nu66ymZk1kVp3ND+dTpt9T7qa2gZg5/LK\nMjOzRqh1TeEUoBX4BHAA8AHgg2UVZWZmjTHkmkL6odrREXEqsAn4UOlVmZlZQwy5phARfwUOqUMt\nZmbWYLXuU7hV0mLgJ8ATfY0RcVkpVZmZWUPUGgo7ARuBtxbaAnAomJk1kVp/0bxd+xEkzSa7QlsL\ncG5EnFExfhbwM+De1HRZRHx5e+ZlZmbPXa2/aP4+2ZpBPxFx4iCPaQHOBg4H1gNLJC2OiBUVXX8d\nEe+pvWQzMytLrZuPfl64vxNwJHDfEI85CFgZEasAJC0C5gCVoWBmZqNErZuPLi0OS7oQ+M0QD5sM\nrCsMrwfeUKXfmyTdRvaDuFMjYnktNZmZ2cirdU2h0gzgxSMw/1uAaRGxSdIRwOVp2v1ImgfMA5g2\nbdoIzNbMzKqp6RfNkh6X9FjfH3AF2TUWBrMBmFoYnpLachHxWERsSvevBHaQNKlyQhHRFREdEdHR\n1tZWS8lmZrYdat18tMt2THsJMEPSXmRhMBc4tthB0kuBByIiJB1EFlIbt2NeZmY2AmpdUzhS0q6F\n4d0kvW+wx0TEFuAk4GrgTuDiiFguab6k+anbUcAdkv4AfAuYGxF/c5STmZnVh2r5DJa0LCL2q2i7\nNSL2L62yAXR0dERPT0+9Z2tmNqZJWhoRHUP1q/UsqdX6be9OajMzG6VqDYUeSWdKekX6OxNYWmZh\nZmZWf7WGwsnAM8BFwCLgKeDjZRVlZmaNUevRR08Ap5Vci5mZNVitRx9dK2m3wvDukq4urywzM2uE\nWjcfTYqIR/sGIuIRRuYXzWZmNorUGgpbJeXnl5DUTpWzppqZ2dhW62GlC4DfSLoBEPD3pHMRmZlZ\n86h1R/NVkjrIguBWshPXPVlmYWZmVn+1XmTnI8ApZCe1WwYcDPyW/pfnNDOzMa7WfQqnAAcCayLi\nMGB/4NHBH2JmZmNNraHwVEQ8BSDpeRFxF7BPeWWZmVkj1LqjeX36ncLlwLWSHgHWlFeWmZk1Qq07\nmo9Md0+X9CtgV+Cq0qoyM7OGGPaZTiPihjIKMTOzxqt1n4KNNd3d0N4OEyZkt93dja7IzMYAXxOh\nGXV3w7x5sHlzNrxmTTYM0NnZuLrMbNTzmkIzWrBgWyD02bw5azczG4RDoRmtXTu8djOzxKHQjKZN\nG167mVniUGhGCxdCa2v/ttbWrN3MbBAOhWbU2QldXTB9OkjZbVeXdzKb2ZB89FGz6ux0CJjZsJW6\npiBptqS7Ja2UNOA1niUdKGmLpKPKrMfMzAZXWihIagHOBt4FzASOkTRzgH7/DFxTVi1mZlabMtcU\nDgJWRsSqiHgGWATMqdLvZOBS4MESazEzsxqUGQqTgXWF4fWpLSdpMnAk8J3BJiRpnqQeST29vb0j\nXqiZmWUaffTRN4DPRcTWwTpFRFdEdERER1tbW51KMzMbf8o8+mgDMLUwPCW1FXUAiyQBTAKOkLQl\nIi4vsS4zMxtAmaGwBJghaS+yMJgLHFvsEBF79d2XdD7wcweCmVnjlBYKEbFF0knA1UALcF5ELJc0\nP40/p6x5m5nZ9in1x2sRcSVwZUVb1TCIiBPKrMXMzIbW6B3NZmY2ijgUzMws51AwM7OcQ8HMzHIO\nBTMzyzkUzMws51AwM7OcQ8HMzHIOBTMzyzkUzMws51AwM7OcQ8HMzHIOBTMzyzkUzMws51AwM7Oc\nQ8HMzHIOBTMzyzkUzMws51AwM7OcQ8HMzHIOBTMzyzkUzMwsV2ooSJot6W5JKyWdVmX8HEm3SVom\nqUfSIWXWY2Zmg5tY1oQltQBnA4cD64ElkhZHxIpCt18CiyMiJP0dcDHwqrJqMjOzwZW5pnAQsDIi\nVkXEM8AiYE6xQ0RsiohIgy8AAjMza5gyQ2EysK4wvD619SPpSEl3Af8BnFhtQpLmpc1LPb29vaUU\na2Zmo2BHc0T8NCJeBbwP+MoAfboioiMiOtra2upboJnZOFJmKGwAphaGp6S2qiLiRuDlkiaVWJOZ\nmQ2izFBYAsyQtJekHYG5wOJiB0mvlKR0//XA84CNJdZkZmaDKO3oo4jYIukk4GqgBTgvIpZLmp/G\nnwP8N+B4Sc8CTwJHF3Y8m5lZnWmsfQZ3dHRET09Po8swMxtTJC2NiI6h+jV8R7OZmY0eDgUzM8s5\nFMzMLOdQMDOznEPBzMxyDgUzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8s5FMzMLOdQMDOznEPBzMxy\nDgUzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8uVGgqSZku6W9JK\nSadVGd8p6TZJt0u6WdK+ZdZjZmaDKy0UJLUAZwPvAmYCx0iaWdHtXuAtEfE64CtAVynFdHdDeztM\nmJDddneXMhszs7FuYonTPghYGRGrACQtAuYAK/o6RMTNhf6/A6aMeBXd3TBvHmzenA2vWZMNA3R2\njvjszMzGsjI3H00G1hWG16e2gXwY+M8Rr2LBgm2B0Gfz5qzdzMz6KXNNoWaSDiMLhUMGGD8PmAcw\nbdq04U187drhtZuZjWNlrilsAKYWhqektn4k/R1wLjAnIjZWm1BEdEVER0R0tLW1Da+KgUJkuOFi\nZjYOlBkKS4AZkvaStCMwF1hc7CBpGnAZcFxE/LGUKhYuhNbW/m2trVm7mZn1U1ooRMQW4CTgauBO\n4OKIWC5pvqT5qdsXgT2Ab0taJqlnxAvp7ISuLpg+HaTstqvLO5nNzKpQRDS6hmHp6OiInp6Rzw4z\ns2YmaWlEdAzVz79oNjOznEPBzMxyDgUzM8s5FMzMLOdQMDOz3Jg7+khSL7Cm0XVsh0nAQ40uos68\nzM1vvC0vjN1lnh4RQ/76d8yFwlglqaeWw8GaiZe5+Y235YXmX2ZvPjIzs5xDwczMcg6F+innAkKj\nm5e5+Y235YUmX2bvUzAzs5zXFMzMLOdQMDOznEOhRJKmSvqVpBWSlks6pdE11YukFkm3Svp5o2up\nB0m7SbpE0l2S7pT0xkbXVDZJn0rv6zskXShpp0bXNNIknSfpQUl3FNpeJOlaSfek290bWeNIcyiU\nawvw6YiYCRwMfFzSzAbXVC+nkF1HY7z4JnBVRLwK2JcmX3ZJk4FPAB0R8VqghexCWs3mfGB2Rdtp\nwC8jYgbwyzTcNBwKJYqIP0fELen+42QfFJMbW1X5JE0B3k12mdWmJ2lX4FDgewAR8UxEPNrYqupi\nIvB8SROBVuC+Btcz4iLiRuDhiuY5wA/S/R8A76trUSVzKNSJpHZgf+D3ja2kLr4BfBbY2uhC6mQv\noBf4ftpkdq6kFzS6qDJFxAbg/wJrgT8Df4mIaxpbVd28JCL+nO7fD7ykkcWMNIdCHUjaGbgU+GRE\nPNboesok6T3AgxGxtNG11NFE4PXAdyJif+AJmmyTQqW0HX0OWSDuCbxA0gcaW1X9RXZMf1Md1+9Q\nKJmkHcgCoTsiLmt0PXXwZuAfJK0GFgFvlfSjxpZUuvXA+ojoWwu8hCwkmtnbgXsjojcingUuA97U\n4Jrq5QFJLwNItw82uJ4R5VAokSSRbWe+MyLObHQ99RARn4+IKRHRTrbj8bqIaOpvkBFxP7BO0j6p\n6W3AigaWVA9rgYMltab3+dto8p3rBYuBD6b7HwR+1sBaRpxDoVxvBo4j+7a8LP0d0eiirBQnA92S\nbgP2A77W4HpKldaKLgFuAW4n+yxputM/SLoQ+C2wj6T1kj4MnAEcLukesjWmMxpZ40jzaS7MzCzn\nNQUzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8s5FMzMLOdQsDFL0qaSp98m6ffpfEZ/X+a8aiXpfElH\nbedjZ0l6U2F4u6dlzWtiowswG8XeBtweER9pdCEjZBawCbi5wXXYKOY1BRsVJJ0h6eOF4dMlnSpp\nZ0m/lHSLpNslzany2FnFi/lIOkvSCen+AZJukLRU0tV956ypeHy7pOsk3ZbmNU3SfsD/AeakX6I/\nv+IxqyV9PY3rkfT6NP0/SZqf+lStXdKBaV47SXpBulDNawd4XpSW525JvwBeXBhXddkkXS/pm6m2\nOyQdlM7SOx/4VGrvW/M5VNLNklZ5rcEAiAj/+a/hf2SnFb+hMLwCmEq2NvvC1DYJWMm2X+JvSrez\ngJ8XHnsWcAKwA9m34rbUfjRwXpV5XwF8MN0/Ebg83T8BOGuAelcDH0v3/w24DdgFaAMeSO2D1f5V\nslNPnw18fpDn5f3AtWQXsdkTeBQ4arBlA64H/j3dPxS4I90/HTi1MO3zgZ+QfTmcCaxs9PvAf43/\n8+YjGxUi4lZJL5a0J9kH6yMRsS6dZfZrkg4luz7DZLLz199fw2T3AV4LXJuds40WsnP/V3oj2Ycv\nwAVkawi1WJxubwd2juxCSo9LelrSbmSn0B6o9i8DS4CnyK5gNpBDgQsj4q/AfZKuq3HZLoTsIjGS\nXpjqqebyiNgKrJDUVNcFsO3jULDR5Cdk34JfClyU2jrJQuKAiHg2nZK78lrAW+i/KbRvvIDlEVHW\n9ZKfTrdbC/f7hicyeO17ADuTfePfiSxAhmOoZas8qdlAJzkr1q1h1mBNyPsUbDS5iOx020eRBQTA\nrmQX7XlW0mHA9CqPWwPMlPS89I34ban9bqBN0hshu7aFpNdUefzNbLu+cCfw6xFZmsFr/y7wT0A3\n8M+DTONG4GhJLWmfwWGpfahlOzq1H0J2VbS/AI+TbeIyG5DXFGzUiIjlknYBNsS2yx12A1dIuh3o\nAe6q8rh1ki4G7gDuBW5N7c+knaffUnYd5YlklwpdXjGJk8kupfkZsstqfmiEFqlq7ZKOB56NiB9L\nagFulvTWiLiuyjR+CryVbB/LWrLTONeybE9JupVsTeTE1HYFcEna4X3yCC2jNRmfOtusyUi6nmyH\nck+ja7Gxx5uPzMws5zUFs1FA0uvIjnwqejoi3tCIemz8ciiYmVnOm4/MzCznUDAzs5xDwczMcg4F\nMzPL/Rd9yJ0JIoBBYQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115072518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot a graph for multiple values for the parameter max_depth\n",
    "def gpDT(X):\n",
    "    DT = tree.DecisionTreeClassifier(max_depth=X)\n",
    "    DT.fit(X_train_mnist, y_train_mnist)\n",
    "    return DT\n",
    "\n",
    "plt.plot([1, 3, 5, 7, 9, 11], [av_accuracy(gpDT(1),X_train_mnist, y_train_mnist), av_accuracy(gpDT(3), X_train_mnist, y_train_mnist), av_accuracy(gpDT(5), X_train_mnist, y_train_mnist), av_accuracy(gpDT(7), X_train_mnist, y_train_mnist), av_accuracy(gpDT(9), X_train_mnist, y_train_mnist), av_accuracy(gpDT(11), X_train_mnist, y_train_mnist)], \"ro\")\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('value of max_depth')\n",
    "plt.title('plot different values for max_depth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.96      0.95        27\n",
      "          1       0.67      0.65      0.66        31\n",
      "          2       0.80      0.74      0.77        27\n",
      "          3       0.59      0.43      0.50        30\n",
      "          4       0.79      0.91      0.85        33\n",
      "          5       0.93      0.87      0.90        30\n",
      "          6       0.93      0.83      0.88        30\n",
      "          7       0.72      0.87      0.79        30\n",
      "          8       0.55      0.64      0.59        28\n",
      "          9       0.73      0.71      0.72        31\n",
      "\n",
      "avg / total       0.76      0.76      0.76       297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Give a classification report \n",
    "y_true_DT = y_test_mnist\n",
    "y_pred_DT = clfDT_opt.predict(X_test_mnist)\n",
    "print(classification_report(y_true_DT, y_pred_DT, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26  0  0  0  0  0  0  1  0  0]\n",
      " [ 0 20  3  1  1  0  0  0  5  1]\n",
      " [ 1  1 20  2  0  0  1  2  0  0]\n",
      " [ 0  2  1 13  1  2  0  2  7  2]\n",
      " [ 0  0  0  0 30  0  0  2  0  1]\n",
      " [ 0  0  0  1  1 26  1  0  0  1]\n",
      " [ 0  1  0  0  2  0 25  0  2  0]\n",
      " [ 0  0  0  2  1  0  0 26  0  1]\n",
      " [ 1  4  1  1  0  0  0  1 18  2]\n",
      " [ 0  2  0  2  2  0  0  2  1 22]]\n"
     ]
    }
   ],
   "source": [
    "#give the confusion matrix\n",
    "print(confusion_matrix(y_true_DT, y_pred_DT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have tuned the parameter max_depth. We see that the accuracy gets higher as the max_depth gets higher. \n",
    "\n",
    "We see that the accuracies of the Decision tree classifier are lower than the accuracies of K-nn classifier or Logistic regression, namely .83 on the training set and 0.76 on the test set\n",
    "\n",
    "We see in the classification report that the recall and prediction value are never 1, meaning that for every class we misclassify instances. \n",
    "\n",
    "In the confusion matrix we see that expecially a lot (7) of 3's are being classified as 8's. Moreover, five 1's are being classified as 8's and four 8's are being classified as 1's. \n",
    "\n",
    "We thus see again that a lot of 3's are being classified as 8's, which we also had for the Logistic Regression classifier, but the decision tree classifier also mixes up the 1's and the 8's. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus, Neural Networks classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.954871887964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "NN = MLPClassifier()\n",
    "NN = NN.fit(X_train_mnist, y_train_mnist) #train the MPLclassifier on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#we find the optimal values for the parameters of the Neural Network classifier\n",
    "parametersNNA = {'activation' : ('identity', 'logistic', 'tanh', 'relu')}\n",
    "clfNNA = GridSearchCV(NN, parametersNNA)\n",
    "clfNNA.fit(X_train_mnist, y_train_mnist)\n",
    "print(clfNNA.best_params_)\n",
    "\n",
    "parametersNN_MI = {'max_iter': np.arange(100,300)}\n",
    "clfNN_MI = GridSearchCV(NN, parametersNN_MI)\n",
    "clfNN_MI.fit(X_train_mnist, y_train_mnist)\n",
    "print(clfNN_MI.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy under Neural Networks with default parameters is:                         0.954285948319\n",
      "The standard deviation under Neural Networks with default parameters is:                       0.028035363294 \n",
      "\n",
      "The average accuracy under Neural Networks with optimized parameters is:                       0.937027029124\n",
      "The standard deviation under Neural Networks with optimized parameters is:                     0.041848027682 \n",
      "\n",
      "The average accuracy under Neural Networks with default parameters is on the test set:         0.916786528883\n",
      "The standard deviation under Neural Networks with default parameters is on the test set:       0.0469678269017 \n",
      "\n",
      "The average accuracy under Neural Networks with optimized parameters is on the test set:       0.946485903583\n",
      "The standard deviation under Neural Networks with optimized parameters is on the test set:     0.0305657374555 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The average accuracy under Neural Networks with default parameters is:                        \", \n",
    "      av_accuracy(NN, X_train_mnist, y_train_mnist))\n",
    "print(\"The standard deviation under Neural Networks with default parameters is:                      \", \n",
    "      standarddev(NN, X_train_mnist, y_train_mnist),\n",
    "     \"\\n\")\n",
    "\n",
    "#Train Neural Networks using optimized parameters on the test set.\n",
    "NN_opt = MLPClassifier(activation = 'logistic', max_iter=1000)\n",
    "NN_opt.fit(X_train_mnist, y_train_mnist)\n",
    "\n",
    " \n",
    "print(\"The average accuracy under Neural Networks with optimized parameters is:                      \", \n",
    "      av_accuracy(NN_opt, X_test_mnist, y_test_mnist))\n",
    "print(\"The standard deviation under Neural Networks with optimized parameters is:                    \", \n",
    "      standarddev(NN_opt, X_test_mnist, y_test_mnist),\n",
    "     \"\\n\")\n",
    "\n",
    "\n",
    "#now print the scores on your test set\n",
    "print(\"The average accuracy under Neural Networks with default parameters is on the test set:        \", \n",
    "      av_accuracy(NN, X_test_mnist, y_test_mnist))\n",
    "print(\"The standard deviation under Neural Networks with default parameters is on the test set:      \", \n",
    "      standarddev(NN, X_test_mnist, y_test_mnist),\n",
    "     \"\\n\")\n",
    "print(\"The average accuracy under Neural Networks with optimized parameters is on the test set:      \", \n",
    "      av_accuracy(NN_opt, X_test_mnist, y_test_mnist))\n",
    "print(\"The standard deviation under Neural Networks with optimized parameters is on the test set:    \", \n",
    "      standarddev(NN_opt, X_test_mnist, y_test_mnist),\n",
    "     \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1152257b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot graph for different \"values\" of the activation function\n",
    "def gpNN(X):\n",
    "    NN = MLPClassifier(activation=X)\n",
    "    NN.fit(X_train_mnist, y_train_mnist)\n",
    "    return NN\n",
    "\n",
    "plt.plot([1, 2, 3, 4], [av_accuracy(gpNN('logistic'),X_train_mnist, y_train_mnist), av_accuracy(gpNN('relu'), X_train_mnist, y_train_mnist), av_accuracy(gpNN('identity'), X_train_mnist, y_train_mnist), av_accuracy(gpNN('tanh'), X_train_mnist, y_train_mnist)], \"ro\")\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('value of for the activation function') #here 1 represents \"logistic\", 2 \"relu\", 3 \"identity\" and 4 \"tahn\n",
    "plt.title('plot different values for different activation functions ')\n",
    "plt.show()   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96        27\n",
      "          1       0.91      0.97      0.94        31\n",
      "          2       0.96      1.00      0.98        27\n",
      "          3       1.00      0.67      0.80        30\n",
      "          4       0.88      0.91      0.90        33\n",
      "          5       0.83      1.00      0.91        30\n",
      "          6       0.97      0.97      0.97        30\n",
      "          7       0.90      0.93      0.92        30\n",
      "          8       0.74      0.89      0.81        28\n",
      "          9       1.00      0.84      0.91        31\n",
      "\n",
      "avg / total       0.92      0.91      0.91       297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Give a classification report \n",
    "y_true_NN = y_test_mnist\n",
    "y_pred_NN = NN.predict(X_test_mnist)\n",
    "print(classification_report(y_true_NN, y_pred_NN, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25  0  0  0  1  0  1  0  0  0]\n",
      " [ 0 30  0  0  1  0  0  0  0  0]\n",
      " [ 0  0 27  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 20  0  3  0  2  4  0]\n",
      " [ 0  1  0  0 30  0  0  0  2  0]\n",
      " [ 0  0  0  0  0 30  0  0  0  0]\n",
      " [ 0  1  0  0  0  0 29  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 28  1  0]\n",
      " [ 0  1  0  0  1  1  0  0 25  0]\n",
      " [ 0  0  0  0  0  2  0  1  2 26]]\n"
     ]
    }
   ],
   "source": [
    "#give the confusion matrix\n",
    "print(confusion_matrix(y_true_NN, y_pred_NN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Neural Networks classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the accuracies of the Neural Network Classifier are high, and aproximately equally as high as those of the K-nn classifier and Logistic Regression classifier. \n",
    "\n",
    "In our plot we see that the \"logistic\" activation function results in a high accuracy and the \"identity\" activation function in a lower accuracy. However, that accuracy is still 0.94 which is high as well. \n",
    "\n",
    "When we look at the classification report, we see that all the precision and recall scores are reasonably high, except for the recall score of class 3 and the precision score of 8, they are much lower.\n",
    "\n",
    "In the confusion matrix we see again that four 3's are being misclassified as 8's, just like in the logisitc regression classifier and the decision tree classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus, Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy under Naive Bayes with default parameters is:                                    0.843732737128\n",
      "The standard deviation under Naive Bayes with default parameters is:                                  0.0536649233545 \n",
      "\n",
      "The average accuracy under Naive Bayes with default parameters on test set is:                        0.832724402241\n",
      "The standard deviation under Naive Bayes with default parameters on test set is:                      0.0481905318579 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_mnist, y_train_mnist) #train the GaussianNB classifier using default settings on the training set\n",
    "\n",
    "#print the accuracies and standard deviation using default settings on the train and test set\n",
    "print(\"The average accuracy under Naive Bayes with default parameters is:                                   \", \n",
    "      av_accuracy(gnb, X_train_mnist, y_train_mnist))\n",
    "print(\"The standard deviation under Naive Bayes with default parameters is:                                 \", \n",
    "      standarddev(gnb, X_train_mnist, y_train_mnist),\n",
    "     \"\\n\")\n",
    "\n",
    "print(\"The average accuracy under Naive Bayes with default parameters on test set is:                       \", \n",
    "      av_accuracy(gnb, X_test_mnist, y_test_mnist))\n",
    "print(\"The standard deviation under Naive Bayes with default parameters on test set is:                     \", \n",
    "      standarddev(gnb, X_test_mnist, y_test_mnist),\n",
    "     \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gaussian Naive Bayes classifier does not have any other parameters than the prior parameter, which we cannot tune. Therefore we cannot perform this stap op the Gaussian Naive Bayes classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96        27\n",
      "          1       0.69      0.87      0.77        31\n",
      "          2       0.95      0.70      0.81        27\n",
      "          3       1.00      0.47      0.64        30\n",
      "          4       0.96      0.82      0.89        33\n",
      "          5       0.78      0.93      0.85        30\n",
      "          6       0.97      0.97      0.97        30\n",
      "          7       0.59      0.87      0.70        30\n",
      "          8       0.56      0.71      0.63        28\n",
      "          9       0.91      0.68      0.78        31\n",
      "\n",
      "avg / total       0.84      0.80      0.80       297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Give the classification report \n",
    "y_true_gnb = y_test_mnist\n",
    "y_pred_gnb = gnb.predict(X_test_mnist)\n",
    "print(classification_report(y_true_gnb, y_pred_gnb, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 27  0  0  0  0  0  0  4  0]\n",
      " [ 0  4 19  0  0  0  1  0  1  2]\n",
      " [ 0  1  0 14  0  4  0  3  8  0]\n",
      " [ 0  0  0  0 27  0  0  5  1  0]\n",
      " [ 0  1  0  0  0 28  0  1  0  0]\n",
      " [ 0  1  0  0  0  0 29  0  0  0]\n",
      " [ 0  0  1  0  0  1  0 26  2  0]\n",
      " [ 0  4  0  0  0  1  0  3 20  0]\n",
      " [ 1  1  0  0  0  2  0  6  0 21]]\n"
     ]
    }
   ],
   "source": [
    "#Give the confusion matrix\n",
    "print(confusion_matrix(y_true_gnb, y_pred_gnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see that the accuracies of the Naive Bayes classifier are lower than K-nn, Logistic Regression and Neural networks, but higher than the of the decision tree classifier. \n",
    "\n",
    "Again, this classifier misclassifies many (8) 3's as 8's as we can see in the confusion matrix. Moreover, this classifier also misclassifies six 9's as 7's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 7}\n",
      "{'C': 0.001}\n"
     ]
    }
   ],
   "source": [
    "#Bonus try iris dataset.\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data[:, :3] \n",
    "Y = iris.target\n",
    "\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(X, Y, test_size=0.5)\n",
    "\n",
    "KnnI = KNeighborsClassifier()\n",
    "parametersK = {'n_neighbors': np.arange(1,10)}\n",
    "clfK = GridSearchCV(Knn, parametersK)\n",
    "clfK.fit(X_train_iris, y_train_iris)\n",
    "print(clfK.best_params_)\n",
    "\n",
    "LRI = LogisticRegression()\n",
    "parametersL = {'C': np.arange(0.001, 10)}\n",
    "clf = GridSearchCV(LR, parametersL) \n",
    "clf.fit(X_train_iris, y_test_iris)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy under Logistic Regression with default parameters on the iris dataset is:          0.895833333333\n",
      "The standard deviation under Logistic Regression with optimized parameters on the irisdata set is:      0.0773923984209 \n",
      "\n",
      "The average accuracy under K-nn with default parameters on the iris dataset is:                         0.920833333333\n",
      "The standard deviation under K-nn with default parameters is:                                           0.0863013132384 \n",
      "\n",
      "The average accuracy under Logistic Regression with optimized parameters on the iris dataset is:        0.908333333333\n",
      "The standard deviation under Logistic Regression with optimized parameters on the iris dataset is:      0.0829156197589 \n",
      "\n",
      "The average accuracy under K-nn with optimized parameters on the iris dataset is:                       0.946666666667\n",
      "The standard deviation under K-nn with optimized parameters on the iris dataset is:                     0.0516397779494\n"
     ]
    }
   ],
   "source": [
    "print(\"The average accuracy under Logistic Regression with default parameters on the iris dataset is:         \", \n",
    "      av_accuracy(LRI, X_train_iris, y_train_iris))\n",
    "print(\"The standard deviation under Logistic Regression with optimized parameters on the irisdata set is:     \", \n",
    "      standarddev(LR, X_train_iris, y_train_iris),\n",
    "     \"\\n\")\n",
    "\n",
    "print(\"The average accuracy under K-nn with default parameters on the iris dataset is:                        \", \n",
    "      av_accuracy(KnnI, X_train_iris, y_train_iris))\n",
    "print(\"The standard deviation under K-nn with default parameters is:                                          \", \n",
    "      standarddev(Knn, X_train_iris, y_train_iris),\n",
    "     \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#Train logistic regression and k-nn using optimized parameters.\n",
    "LR_optI = LogisticRegression(C=10)\n",
    "LR_optI.fit(X, Y)\n",
    "\n",
    "\n",
    "print(\"The average accuracy under Logistic Regression with optimized parameters on the iris dataset is:       \", \n",
    "      av_accuracy(LR_optI, X_train_iris, y_train_iris))\n",
    "print(\"The standard deviation under Logistic Regression with optimized parameters on the iris dataset is:     \", \n",
    "      standarddev(LR_optI, X_train_iris, y_train_iris),\n",
    "     \"\\n\")\n",
    "\n",
    "Knn_optI = KNeighborsClassifier(n_neighbors=7)\n",
    "Knn_optI.fit = (X_train_iris, y_train_iris)\n",
    "\n",
    "print(\"The average accuracy under K-nn with optimized parameters on the iris dataset is:                      \", \n",
    "      av_accuracy(Knn_optI, X, Y))\n",
    "print(\"The standard deviation under K-nn with optimized parameters on the iris dataset is:                    \", \n",
    "      standarddev(Knn_opt, X, Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmaFOJCYmVkhDiRmZlaIA4mZmRXyP8sn1eawFwhWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114e749b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([1, 2, 3, 4,5,6,7], [av_accuracy(Knn_optI, X, Y), av_accuracy(Knn2, X, Y), av_accuracy(Knn3, X, Y), av_accuracy(Knn4, X, Y), av_accuracy(Knn5, X, Y), av_accuracy(Knn6, X, Y), av_accuracy(Knn7, X, Y)], \"ro\")\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('value of k')\n",
    "plt.title('plot different values for k, the number of neighbors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1131c5748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "plt.plot([0.01, 0.05, 0.07, 0.1, 0.3, 0.5, 0.7, 1], [av_accuracy(LR_optI, X, Y), av_accuracy(LR2, X, Y), av_accuracy(LR3, X, Y), av_accuracy(LR5, X, Y), av_accuracy(LR6, X, Y), av_accuracy(LR7, X, Y), av_accuracy(LR8, X, Y), av_accuracy(LR9, X, Y)], 'ro')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('value of C')\n",
    "plt.title('plot different values for C')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_namesI = ['0', '1', '2']\n",
    "y_true_knnI = y_test_iris\n",
    "knn_optI = KNeighborsClassifier(n_neighbors=2)\n",
    "knn_optI.fit(X_test_iris, y_test_iris)\n",
    "y_pred_knnI = knn_optI.predict(X_test_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        27\n",
      "          1       0.92      1.00      0.96        24\n",
      "          2       1.00      0.92      0.96        24\n",
      "\n",
      "avg / total       0.98      0.97      0.97        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true_knnI, y_pred_knnI, target_names=target_namesI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  0  0]\n",
      " [ 0 24  0]\n",
      " [ 0  2 22]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_true_knnI, y_pred_knnI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        27\n",
      "          1       0.91      0.83      0.87        24\n",
      "          2       0.85      0.92      0.88        24\n",
      "\n",
      "avg / total       0.92      0.92      0.92        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true_LRI = y_test_iris\n",
    "y_pred_LRI = LR_optI.predict(X_test_iris) \n",
    "print(classification_report(y_true_LR, y_pred_LR, target_names=target_namesI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  0  0]\n",
      " [ 0 20  4]\n",
      " [ 0  2 22]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_true_LRI, y_pred_LRI))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis Iris dataset\n",
    "\n",
    "If we look at the plotted values for different values of k for K-nn classifier, we see that generally the accuracy is higher if we have a higher k. However, the accuracy of k=1, k=2, k=4 is almost equal, and the accuracy of k=3, k=5, k=6, k=7 is also almost equally as high. It thus seems as if there is some sort of treashold that we need to pass, and then the accuracy \"jumps\" up. Here we see as well that the accuracy of k=3 (which is an odd number) is higher than the accuracy for k=4(which is an even number). This supports the claim that the accuracy of the K-nn classifier is slightly higher for odd numbers than for even numbers if the numbers are close to eachother. \n",
    "\n",
    "When we look at the classification report of the K-nn classifier, we see that for class 0, every instance is being classified correcly, since the prediction, recall and f1-score are all 1.\n",
    "For class 1 we see that the recall score is 0.92, which means that some instances are being classified as class 1 by the K-nn classifier while they actually do not belong to class 1. We see that the recall score for class 1, which means that everything that belongs to class 1, is also classified as belonging to class 1. \n",
    "\n",
    "Since the f1 score is the harmonic average of the recall and precision score, it makes sense that this is 96\n",
    "\n",
    "For class 3 we see that the precision score is 1, which means that everything that is classified as class 3, belongs also actually to class 3. However, we see that the recall score is 0.92, which means that 8% of the instances that belong to class 3 are not classified as belonging to class 3. \n",
    "\n",
    "After this we suspect that some instances of class 3 are being classified as instances of class 2.\n",
    "\n",
    "When we look at the confusion matrix, we see indeed that 2 instances that belong to class 3 are being classied as belonging to class 2\n",
    "\n",
    "\n",
    "If we look at the plotted values for different values of c for the Logistic Regression classifier, we see that the accuracy very high for very small values of c, then it reaches a minimum, and then for higher values of C, the accuracy goes up again. We see that the minimum is when C=0.07, just as for the mnist data set.\n",
    "\n",
    "if we look at the classification report of the Logistic classifier, we see that again that for class 0, every instance is being classified correctly, since the prediction, recall and f1-score are all 1.\n",
    "For class 1 we see that the prediction and recall are 0.91 and 0.83 respectifely. We thus see that 9% of the instances that is being classified as class 1 actually does not belong to class 1, and 17% of the items that belong to class 1 are being classified as not belonging to class 1\n",
    "\n",
    "For class 2 we see that the prediction and recall are 0.85 and 0.92 respectively. Therefore 15% of the instances that are being classified as belonging to class 2 actually do not belong to class 2, and 8% of the instances that belong to class 2 are classified as not belonging to class 2. \n",
    "\n",
    "Therefore we assume that items from class 1 are being classified as class 2 and the other way around.\n",
    "\n",
    "If we look at the confusion matrix, we indeed see that 4 items that are actually class 2 are being classified as class 3, and 2 items that are class 3 are being classified as class 2. \n",
    "\n",
    "We see that for both the K-nn classifier and the Logistic classifier that the accuracies are lower \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOTAL ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, we see that the K-nn classifier classifies our data the best "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
